<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>LeRobot SmolVLAï¼šä»è®­ç»ƒåˆ°æ¨ç†é“¾è·¯å‰–æ - Laumyçš„æŠ€æœ¯æ ˆ</title>
    <link rel="stylesheet" href="assets/style.css">
    <!-- MathJaxæ”¯æŒLaTeXæ•°å­¦å…¬å¼ -->
    <script>
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          ignoreHtmlClass: 'tex2jax_ignore',
          processHtmlClass: 'tex2jax_process'
        }
      };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <header class="site-header">
      <div class="container">
        <a class="logo" href="./">Laumyçš„æŠ€æœ¯æ ˆ</a>
        <div class="search">
          <input id="search-input" type="text" placeholder="è¾“å…¥å…³é”®è¯å›è½¦æœç´¢">
        </div>
        <div class="theme-toggle" title="åˆ‡æ¢ä¸»é¢˜" id="theme-toggle">â˜¾</div>
        <nav class="top-nav">
          <div class="nav-item"><a href="./">é¦–é¡µ</a></div>
          <div class="nav-item site-link">
            <a href="https://www.laumy.tech" target="_blank" title="è®¿é—®ä¸»ç«™">ä¸»ç«™ç‚¹:www.laumy.tech</a>
          </div>
        </nav>
      </div>
    </header>

    <main class="container layout">
      <aside class="left-nav">
        
        <div class="card">
          <div class="card-title">æ–‡ç« ç›®å½•</div>
          <nav id="toc"><ul><li><a href="#_1">æ¡†æ¶</a><ul></ul></li><li><a href="#_2">è®­ç»ƒ</a><ul><li><a href="#_3">è¾“å…¥å¤„ç†</a></li><li><a href="#_4">å‰å‘ä¼ æ’­</a></li><li><a href="#_5">æŸå¤±è®¡ç®—</a></li><li><a href="#_6">æ¨¡å‹å‚æ•°</a></li></ul></li><li><a href="#_7">æ¨ç†</a><ul><li><a href="#_8">å‰ç¼€ç¼“å­˜</a></li><li><a href="#_9">åç¼€å¾ªç¯</a></li></ul></li><li><a href="#_10">æ³¨æ„åŠ›</a><ul><li><a href="#_11">è‡ªæ³¨æ„åŠ›</a></li><li><a href="#_12">äº¤å‰æ³¨æ„åŠ›</a></li></ul></li><li><a href="#_13">æ¨¡å‹é…ç½®</a><ul><li><a href="#smolvlaconfig">SmolVLAConfig</a></li><li><a href="#_14">åŠ è½½æµç¨‹</a></li></ul></li></ul></nav>
        </div>
        
      </aside>

      <section class="content">
        
<article class="card post">
  <h1>LeRobot SmolVLAï¼šä»è®­ç»ƒåˆ°æ¨ç†é“¾è·¯å‰–æ</h1>
  <div class="meta">
    <span class="meta-item">
      <i class="icon">ğŸ•’</i>
      2025-08-25
    </span>
    <span class="meta-item">
      <i class="icon">ğŸ“‚</i>
      ai
    </span>
    <span class="meta-item">
      <i class="icon">ğŸ‘¤</i>
      laumy
    </span>
  </div>
  <div class="post-content"><h2 id="_1">æ¡†æ¶</h2>
<p>æœ¬æ–‡ä¸»è¦å¯¹lerobot SmolVLAç­–ç•¥ä»£ç è¿›è¡Œåˆ†æï¼Œä¸‹é¢æ˜¯ç­–ç•¥å®ç°å…³é”®éƒ¨åˆ†æ¡†å›¾ã€‚</p>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/08/wp_editor_md_606a482e93c99ec2564559998534915e_1756272535.png"><img alt="" src="assets/doc/04-ai/lerobot/lerobot-smolvlaç­–ç•¥/images/wp_editor_md_606a482e93c99ec2564559998534915e_1756272535.png"/></a></p>
<p>SmolVLAPolicayç±»å°è£…å‘ä¸Šæä¾›ç­–ç•¥çš„è°ƒç”¨ã€‚SmolVLAConfigæ˜¯å¯¹SmolVLAç­–ç•¥çš„é…ç½®ï¼Œç”¨äºé…ç½®è¾“å‡ºåŠ¨ä½œåºåˆ—é•¿åº¦ã€è§‚æµ‹å›¾åƒè¾“å…¥ååˆ°æ¨¡å‹çš„ç¼©æ”¾å°ºå¯¸ä»¥åŠå¾®è°ƒç­–ç•¥ç­‰ç­‰ã€‚SmolVLAPolicayç±»ä¸­å…³é”®çš„æˆå‘˜æ˜¯VLAFlowMatchingç±»ï¼Œæ˜¯å®ç°SmolVLAæ¨¡å‹flow matchingæœºåˆ¶è®­ç»ƒã€æ¨ç†çš„æ ¸å¿ƒã€‚åœ¨VLAFlowMatchingç±»ä¸­å…³ç³»æˆå‘˜æ˜¯SmolVLMWithExpertModelç±»ï¼Œå…¶å®šä¹‰äº†VLM+Expertæ¨¡å‹å…·ä½“å®ç°ã€‚</p>
<p>SmolVLAç­–ç•¥å®ç°ä¸»è¦æ¶‰åŠSmolVLAPolicyã€VLAFlowMatching ã€SmolVLMWithExperModelä¸‰ä¸ªç±»æ¥å®ç°ã€‚å°±ä»¥<strong>æ¨¡å‹è®­ç»ƒã€æ¨¡å‹æ¨ç†</strong>ä¸¤æ¡ä¸»çº¿æ¥è¿›è¡Œæ€»ç»“ã€‚</p>
<h2 id="_2">è®­ç»ƒ</h2>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/08/wp_editor_md_00066daa75db208026c2ad495c61b1cf_1756284915.png"><img alt="" src="assets/doc/04-ai/lerobot/lerobot-smolvlaç­–ç•¥/images/wp_editor_md_00066daa75db208026c2ad495c61b1cf_1756284915.png"/></a></p>
<p>è®­ç»ƒè¿‡ç¨‹å¯ä»¥åˆ†ä¸ºä¸€ä¸‹å‡ ä¸ªæ ¸å¿ƒéƒ¨åˆ†ï¼š</p>
<ul>
<li>æ•°æ®è¾“å…¥å¤„ç†ï¼šå›¾åƒã€æ–‡æœ¬å’ŒçŠ¶æ€é€šè¿‡å„è‡ªå¤„ç†æ–¹æ³•åµŒå…¥å¹¶æ ‡å‡†åŒ–ï¼Œåˆå¹¶æˆç»Ÿä¸€çš„è¾“å…¥ï¼Œä¾›åç»­å±‚æ¬¡å¤„ç†ã€‚</li>
<li>VLMä¸ä¸“å®¶æ¨¡å‹äº¤äº’å‰å‘ä¼ æ’­ï¼šå›¾åƒã€æ–‡æœ¬å’ŒçŠ¶æ€æ•°æ®é€šè¿‡VLMå’Œä¸“å®¶æ¨¡å‹è¿›è¡Œå¤šå±‚æ¬¡çš„è‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›è®¡ç®—ï¼Œå¾—åˆ°è”åˆç‰¹å¾è¡¨ç¤ºã€‚</li>
<li>æŸå¤±è®¡ç®—ä¸ä¼˜åŒ–ï¼šé€šè¿‡è®¡ç®—é¢„æµ‹åŠ¨ä½œå’Œç›®æ ‡åŠ¨ä½œä¹‹é—´çš„æŸå¤±ï¼Œå…·ä½“æ˜¯é€Ÿåº¦åœºçš„æŸå¤±ï¼Œä½¿ç”¨åå‘ä¼ æ’­æ›´æ–°å‚æ•°ã€‚</li>
<li>æ¨¡å‹å‚æ•°å†»ç»“ä¸è®­ç»ƒç­–ç•¥ï¼šé€šè¿‡å†»ç»“ä¸å¿…è¦çš„æ¨¡å‹éƒ¨åˆ†ï¼ˆVLMï¼‰ï¼Œä¸“æ³¨ä¼˜åŒ–é‡è¦éƒ¨åˆ†ï¼Œå‡å°‘è®¡ç®—çš„å¼€é”€ã€‚</li>
</ul>
<h3 id="_3">è¾“å…¥å¤„ç†</h3>
<p>SmolVLAæ¨¡å‹åˆ†ä¸ºå‰ç¼€prefixã€åç¼€suffixè¾“å…¥ã€‚å‰ç¼€ä¸»è¦æ˜¯è§‚æµ‹ç«¯æ•°æ®ç”±å›¾åƒã€æ–‡æœ¬å’Œæœºå™¨çš„çŠ¶æ€åµŒå…¥æ„æˆï¼Œæä¾›ç»™VLMå¤„ç†ï¼Œç›®çš„æ˜¯ä¸ºæ¨¡å‹æä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç†è§£ä»»åŠ¡çš„èƒŒæ™¯ã€‚åç¼€æ˜¯ç”¨äºç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œè¾“å…¥çš„æ˜¯å™ªå£°åŠ¨ä½œ+æ—¶é—´æ­¥ï¼Œç»è¿‡Expertæ¨¡å‹å¤„ç†è¾“å‡ºå…·ä½“çš„é¢„æµ‹åŠ¨ä½œã€‚</p>
<p><strong>ï¼ˆ1ï¼‰å‰ç¼€prefixåµŒå…¥</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">embed_prefix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">img_masks</span><span class="p">,</span> <span class="n">lang_tokens</span><span class="p">,</span> <span class="n">lang_masks</span><span class="p">,</span> <span class="n">state</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pad_masks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">att_masks</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># å¤„ç†å›¾åƒ</span>
    <span class="k">for</span> <span class="n">_img_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">img_mask</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">img_masks</span><span class="p">)):</span>
        <span class="n">img_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">embed_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">embs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img_emb</span><span class="p">)</span>
        <span class="n">pad_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img_mask</span><span class="p">)</span>

    <span class="c1"># å¤„ç†è¯­è¨€</span>
    <span class="n">lang_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">embed_language_tokens</span><span class="p">(</span><span class="n">lang_tokens</span><span class="p">)</span>
    <span class="n">embs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lang_emb</span><span class="p">)</span>
    <span class="n">pad_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lang_masks</span><span class="p">)</span>

    <span class="c1"># å¤„ç†çŠ¶æ€</span>
    <span class="n">state_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_proj</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
    <span class="n">embs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state_emb</span><span class="p">)</span>
    <span class="n">state_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">state_emb</span><span class="p">)</span>
    <span class="n">pad_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state_mask</span><span class="p">)</span>

    <span class="c1"># åˆå¹¶æ‰€æœ‰åµŒå…¥</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">embs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pad_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pad_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">att_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">att_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">embs</span><span class="p">,</span> <span class="n">pad_masks</span><span class="p">,</span> <span class="n">att_masks</span>
</code></pre></div>
<p>ä»£ç çš„æµç¨‹æ˜¯ä¾æ¬¡å¯¹è¾“å…¥å›¾åƒã€è¯­è¨€ã€æœºå™¨çŠ¶æ€è¿›è¡Œåˆ†åˆ«åšembeddingï¼Œç„¶åè¿›è¡ŒæŒ‰åˆ—åˆå¹¶ä¸ºä¸€ä¸ªå‰ç¼€è¾“å…¥ã€‚</p>
<ul>
<li>å›¾åƒåµŒå…¥ï¼šé€šè¿‡embed_imageæ–¹æ³•è½¬æ¢ä¸ºåµŒå…¥è¡¨ç¤ºï¼Œæ¯ä¸ªå›¾åƒçš„åµŒå…¥è¢«æ·»åŠ åˆ°embsåˆ—è¡¨ä¸­ï¼Œimg_maskåˆ™è®°å½•å›¾åƒçš„æœ‰æ•ˆåŒºåŸŸã€‚</li>
<li>æ–‡æœ¬åµŒå…¥ï¼šé€šè¿‡embed_language_tokens() è¢«è½¬æ¢ä¸ºåµŒå…¥è¡¨ç¤ºï¼Œlang_emb æ˜¯è¯­è¨€çš„åµŒå…¥ï¼ŒåŒ…å«äº†è¯­è¨€çš„è¯­æ³•å’Œè¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>çŠ¶æ€åµŒå…¥ï¼šçŠ¶æ€ä¿¡æ¯é€šè¿‡ state_proj() æ˜ å°„åˆ°ä¸å›¾åƒå’Œæ–‡æœ¬ç›¸åŒç»´åº¦çš„ç©ºé—´ï¼Œå¾—åˆ° state_embã€‚</li>
</ul>
<p>æœ€ç»ˆå›¾åƒåµŒå…¥ã€æ–‡æœ¬åµŒå…¥å’ŒçŠ¶æ€åµŒå…¥é€šè¿‡ torch.cat() æ–¹æ³•æŒ‰åˆ—åˆå¹¶æˆä¸€ä¸ªå¤§çš„ å‰ç¼€è¾“å…¥ï¼ˆPrefixï¼‰ã€‚pad_masks å’Œ att_masks ä¹Ÿè¢«åˆå¹¶æˆä¸€ä¸ªç»Ÿä¸€çš„è¾“å…¥ï¼Œç¡®ä¿æ¯ä¸ªæ¨¡æ€çš„ä¿¡æ¯èƒ½å¤Ÿä¸å…¶ä»–æ¨¡æ€çš„è¾“å…¥ä¸€èµ·ä¼ é€’ã€‚</p>
<p>å›¾åƒå’Œæ–‡æœ¬åµŒå…¥è°ƒç”¨å·²ç»éšå¼åŒ…å«äº†ä½ç½®ç¼–ç ï¼ŒçŠ¶æ€ä¿¡æ¯state_proj è½¬æ¢ä¸ºåµŒå…¥ï¼Œå°½ç®¡æ²¡æœ‰æ˜¾å¼çš„ä½ç½®ä¿¡æ¯ï¼Œä½†ä¼šåœ¨æ¨¡å‹ä¸­é€šè¿‡ä¸å…¶ä»–æ¨¡æ€åµŒå…¥çš„èåˆè·å–ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</p>
<p><strong>ï¼ˆ2ï¼‰åç¼€SuffixåµŒå…¥</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">embed_suffix</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">noisy_actions</span><span class="p">,</span> <span class="n">timestep</span><span class="p">):</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pad_masks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">att_masks</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># ä½¿ç”¨ MLP èåˆæ—¶é—´æ­¥é•¿å’ŒåŠ¨ä½œä¿¡æ¯</span>
    <span class="n">action_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_in_proj</span><span class="p">(</span><span class="n">noisy_actions</span><span class="p">)</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">action_emb</span><span class="o">.</span><span class="n">device</span>
    <span class="n">bsize</span> <span class="o">=</span> <span class="n">action_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">action_emb</span><span class="o">.</span><span class="n">dtype</span>
    <span class="c1"># ä½¿ç”¨æ­£å¼¦-ä½™å¼¦ä½ç½®ç¼–ç ç”Ÿæˆæ—¶é—´åµŒå…¥</span>
    <span class="n">time_emb</span> <span class="o">=</span> <span class="n">create_sinusoidal_pos_embedding</span><span class="p">(</span>
        <span class="n">timestep</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">expert_hidden_size</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">min_period</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_period</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">time_emb</span> <span class="o">=</span> <span class="n">time_emb</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="c1"># å°†æ—¶é—´åµŒå…¥å’ŒåŠ¨ä½œåµŒå…¥ç»“åˆ</span>
    <span class="n">time_emb</span> <span class="o">=</span> <span class="n">time_emb</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">expand_as</span><span class="p">(</span><span class="n">action_emb</span><span class="p">)</span>
    <span class="n">action_time_emb</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">action_emb</span><span class="p">,</span> <span class="n">time_emb</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">action_time_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_time_mlp_in</span><span class="p">(</span><span class="n">action_time_emb</span><span class="p">)</span>
    <span class="n">action_time_emb</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">silu</span><span class="p">(</span><span class="n">action_time_emb</span><span class="p">)</span>  <span class="c1"># swish == silu</span>
    <span class="n">action_time_emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_time_mlp_out</span><span class="p">(</span><span class="n">action_time_emb</span><span class="p">)</span>

    <span class="c1"># å°†ç”Ÿæˆçš„åŠ¨ä½œåµŒå…¥åŠ å…¥åˆ°è¾“å…¥ä¸­</span>
    <span class="n">embs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action_time_emb</span><span class="p">)</span>

    <span class="n">bsize</span><span class="p">,</span> <span class="n">action_time_dim</span> <span class="o">=</span> <span class="n">action_time_emb</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">action_time_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">bsize</span><span class="p">,</span> <span class="n">action_time_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">pad_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action_time_mask</span><span class="p">)</span>

    <span class="c1"># è®¾ç½®æ³¨æ„åŠ›æ©ç ï¼Œé˜²æ­¢å›¾åƒã€è¯­è¨€å’ŒçŠ¶æ€çš„è¾“å…¥ä¸åŠ¨ä½œè¾“å…¥ç›¸äº’å½±å“</span>
    <span class="n">att_masks</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">chunk_size</span>
    <span class="n">embs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">embs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pad_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">pad_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">att_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">att_masks</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">embs</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">embs</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="n">att_masks</span> <span class="o">=</span> <span class="n">att_masks</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">bsize</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">att_masks</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">embs</span><span class="p">,</span> <span class="n">pad_masks</span><span class="p">,</span> <span class="n">att_masks</span>
</code></pre></div>
<p>åç¼€çš„è¾“å…¥ä¸»è¦æ˜¯æä¾›ç»™Expertä¸“å®¶æ¨¡å‹ç”¨äºflow matchingé¢„æµ‹å‡ºè¾“å‡ºï¼Œè¾“å…¥æ˜¯å™ªå£°åŠ¨ä½œï¼ˆnoisy actionsï¼‰+æ—¶é—´æ­¥é•¿ï¼ˆtimestepï¼‰ã€‚ä¸Šè¿°ä»£ç å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š</p>
<ul>
<li>æ—¶é—´æ­¥é•¿åµŒå…¥ï¼šæ—¶é—´æ­¥é•¿ï¼ˆtimestepï¼‰ç”¨äºè¡¨ç¤ºå½“å‰çš„ç”Ÿæˆæ­¥éª¤ï¼Œç”Ÿæˆä¸€ä¸ªæ­£å¼¦-ä½™å¼¦ä½ç½®ç¼–ç ï¼ˆSine-Cosine Positional Embeddingï¼‰ã€‚create_sinusoidal_pos_embedding() ä½¿ç”¨æ­£å¼¦å’Œä½™å¼¦å‡½æ•°ç”Ÿæˆæ—¶é—´åµŒå…¥ï¼Œå¢å¼ºæ¨¡å‹å¯¹æ—¶åºçš„ç†è§£ã€‚</li>
<li>åŠ¨ä½œåµŒå…¥ï¼šåŠ¨ä½œé€šè¿‡ action_in_proj è¿›è¡ŒåµŒå…¥ï¼Œå¾—åˆ° action_embã€‚è¿™ä¸€æ­¥æ˜¯å°†ç”Ÿæˆçš„åŠ¨ä½œï¼ˆé‡‡æ ·çš„å™ªå£°åŠ¨ä½œï¼‰è½¬åŒ–ä¸ºåµŒå…¥è¡¨ç¤ºã€‚</li>
<li>èåˆæ—¶é—´å’ŒåŠ¨ä½œï¼šåŠ¨ä½œåµŒå…¥ä¸æ—¶é—´åµŒå…¥ï¼ˆtime_embï¼‰é€šè¿‡ torch.cat() è¿›è¡Œæ‹¼æ¥ï¼Œå½¢æˆä¸€ä¸ªæ–°çš„åŒ…å«æ—¶é—´ä¿¡æ¯çš„åŠ¨ä½œåµŒå…¥ã€‚è¿™æ ·ï¼Œç”Ÿæˆçš„åŠ¨ä½œä¸ä»…åŒ…å«æ¥è‡ªç¯å¢ƒçš„ä¿¡æ¯ï¼Œè¿˜åŠ å…¥äº†æ—¶é—´æ­¥é•¿çš„å˜åŒ–ã€‚</li>
<li>MLPå¤„ç†ï¼šåˆå¹¶åçš„åŠ¨ä½œåµŒå…¥é€šè¿‡ action_time_mlp_in å’Œ action_time_mlp_out å±‚è¿›è¡Œå¤„ç†ã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯å¯¹åŠ¨ä½œåµŒå…¥è¿›è¡Œè¿›ä¸€æ­¥çš„å¤„ç†ï¼Œç¡®ä¿å…¶èƒ½å¤Ÿé€‚åº”åç»­çš„ç”Ÿæˆä»»åŠ¡ã€‚</li>
</ul>
<p>æœ€ç»ˆï¼Œç”Ÿæˆçš„åŠ¨ä½œåµŒå…¥è¢«åŠ å…¥åˆ° embs åˆ—è¡¨ä¸­ï¼Œå¹¶é€šè¿‡ torch.cat() åˆå¹¶ä¸ºä¸€ä¸ªç»Ÿä¸€çš„åç¼€è¾“å…¥ã€‚è¿™ä¸ªåç¼€è¾“å…¥å°†ä¸å‰ç¼€è¾“å…¥ä¸€èµ·é€šè¿‡ Transformer å±‚è¿›è¡Œå¤„ç†ã€‚</p>
<h3 id="_4">å‰å‘ä¼ æ’­</h3>
<p>forwardæ˜¯æ•´ä¸ªå‰å‘ä¼ æ’­çš„æ ¸å¿ƒï¼Œå°†å°†è¾“å…¥ç»„åˆåé€šè¿‡æ¨¡å‹è®¡ç®—è¾“å‡ºã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">img_masks</span><span class="p">,</span> <span class="n">lang_tokens</span><span class="p">,</span> <span class="n">lang_masks</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
    <span class="c1"># 1. å‰ç¼€è¾“å…¥çš„ç”Ÿæˆ</span>
    <span class="n">prefix_embs</span><span class="p">,</span> <span class="n">prefix_pad_masks</span><span class="p">,</span> <span class="n">prefix_att_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_prefix</span><span class="p">(</span>
        <span class="n">images</span><span class="p">,</span> <span class="n">img_masks</span><span class="p">,</span> <span class="n">lang_tokens</span><span class="p">,</span> <span class="n">lang_masks</span><span class="p">,</span> <span class="n">state</span>
    <span class="p">)</span>

    <span class="c1"># 2. åç¼€è¾“å…¥çš„ç”Ÿæˆ</span>
    <span class="n">suffix_embs</span><span class="p">,</span> <span class="n">suffix_pad_masks</span><span class="p">,</span> <span class="n">suffix_att_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_suffix</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>

    <span class="c1"># 3. æ‹¼æ¥å‰ç¼€å’Œåç¼€çš„åµŒå…¥</span>
    <span class="n">pad_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prefix_pad_masks</span><span class="p">,</span> <span class="n">suffix_pad_masks</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">att_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prefix_att_masks</span><span class="p">,</span> <span class="n">suffix_att_masks</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># 4. è®¡ç®—æ³¨æ„åŠ›æ©ç </span>
    <span class="n">att_2d_masks</span> <span class="o">=</span> <span class="n">make_att_2d_masks</span><span class="p">(</span><span class="n">pad_masks</span><span class="p">,</span> <span class="n">att_masks</span><span class="p">)</span>
    <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pad_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># 5. å‰å‘è®¡ç®—</span>
    <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">suffix_out</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">att_2d_masks</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="o">=</span><span class="p">[</span><span class="n">prefix_embs</span><span class="p">,</span> <span class="n">suffix_embs</span><span class="p">],</span>
        <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fill_kv_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># 6. é€Ÿåº¦åœºé¢„æµ‹è®¡ç®—æŸå¤±</span>
    <span class="n">suffix_out</span> <span class="o">=</span> <span class="n">suffix_out</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">chunk_size</span> <span class="p">:]</span>
    <span class="n">suffix_out</span> <span class="o">=</span> <span class="n">suffix_out</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">v_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_out_proj</span><span class="p">(</span><span class="n">suffix_out</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">v_t</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">"none"</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">losses</span>
</code></pre></div>
<p>ä»£ç è°ƒç”¨å‰ç¼€ã€åç¼€è¾“å…¥ç„¶åè¿›è¡Œæ‹¼æ¥å¾—åˆ°inputs_embedsï¼Œç„¶åå†è®¡ç®—æ³¨æ„åŠ›çš„æ©ç å°±å¯ä»¥è°ƒç”¨VLM+Expertæ¨¡å‹è¿›è¡Œå‰å‘è®¡ç®—ã€‚åœ¨å‰å‘è®¡ç®—ä¸­æœ‰ä¸¤ä¸ªå‚æ•°use_cache å’Œ fill_kv_cache å‚æ•°ï¼Œè¿™ä¸¤ä¸ªå‚æ•°çš„è®¾ç½®æ§åˆ¶ key-value ç¼“å­˜ çš„ä½¿ç”¨ã€‚</p>
<p><strong>ï¼ˆ1ï¼‰æ¨¡å‹ç»„åˆ</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_vlm_model</span><span class="p">()</span><span class="o">.</span><span class="n">text_model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_expert</span><span class="p">]</span>
<span class="n">model_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_model_layers</span><span class="p">(</span><span class="n">models</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_model_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">models</span><span class="p">:</span> <span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">:</span>
        <span class="n">vlm_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">expert_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">multiple_of</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_vlm_layers</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_expert_layers</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_vlm_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">multiple_of</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">multiple_of</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">expert_layer</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">expert_layer_index</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="n">multiple_of</span> <span class="k">if</span> <span class="n">multiple_of</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">i</span>
                <span class="n">expert_layer</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">expert_layer_index</span><span class="p">]</span>
            <span class="n">vlm_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">expert_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">expert_layer</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">vlm_layers</span><span class="p">,</span> <span class="n">expert_layers</span><span class="p">]</span>
</code></pre></div>
<p>æ¨¡å‹æ··åˆä¸»è¦æ˜¯ç”Ÿæˆä¸€ä¸ªæ··åˆçš„æ¨¡å‹å±‚åˆ—è¡¨ï¼Œé€šè¿‡get_model_layerså‡½æ•°è®¡ç®—å¹¶è¿”å› VLM å±‚å’Œ Expert å±‚çš„å¯¹é½å…³ç³»ï¼ŒVLMå±‚å’ŒExpertå±‚å¯¹é½æ˜¯åŸºäºmultiple_ofæ¥è¿›è¡Œå±‚çº§åˆ†é…çš„ã€‚å¦‚æœæŸäº› VLM å±‚ æ²¡æœ‰å¯¹åº”çš„ Expert å±‚ï¼Œåˆ™è®¾ç½®ä¸º Noneï¼Œä»…ç”± VLM å±‚å¤„ç†ã€‚é»˜è®¤æƒ…å†µä¸‹VLMå’ŒExpertçš„å±‚æ•°ä¸€æ ·éƒ½ä¸º16ï¼Œä¸‹å›¾çœ‹çœ‹VLM=8ï¼ŒExpert=4çš„ç¤ºä¾‹ã€‚</p>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/08/wp_editor_md_21c7ee411d6eafe7cc1c5679d1ca2d38_1756209942.png"><img alt="" src="assets/doc/04-ai/lerobot/lerobot-smolvlaç­–ç•¥/images/wp_editor_md_21c7ee411d6eafe7cc1c5679d1ca2d38_1756209942.png"/></a></p>
<p>å› æ­¤æœ€ç»ˆå¯¹äºSmolVLAæ¥è¯´ï¼Œæ¨¡å‹æ˜¯ä¸€ä¸ªæ··åˆçš„æ¨¡å‹å±‚åˆ—è¡¨model_layersã€‚å¯ä»¥é€šè¿‡model_layers[i][layer_idx]æ¥è®¿é—®å…·ä½“çš„æ¨¡å‹ï¼Œmodel_layers[0][x]ä¸ºVLMæ¨¡å‹ï¼Œmodel_layers[1][x]ä¸ºExpertæ¨¡å‹ã€‚å¦‚model_layers[0][2]ä¸ºç¬¬äºŒå±‚çš„VLMï¼Œmodel_layers[1][2]ä¸ºç¬¬äºŒå±‚çš„Expertï¼Œmodel_layers[1][1]ä¸ºNoneã€‚</p>
<p><strong>ï¼ˆ2ï¼‰å¤„ç†è¾“å…¥åµŒå…¥</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">for</span> <span class="n">hidden_states</span> <span class="ow">in</span> <span class="n">inputs_embeds</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">hidden_states</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">continue</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<p>éå†è¾“å…¥åµŒå…¥ï¼ˆinputs_embedsï¼‰ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ— æ•ˆçš„è¾“å…¥ï¼ˆå³ Noneï¼‰ï¼Œå¹¶è·å–å½“å‰æ‰¹æ¬¡çš„å¤§å°batch_sizeã€‚</p>
<ul>
<li>inputs_embedsï¼šæ¨¡å‹çš„è¾“å…¥åµŒå…¥æ•°æ®ï¼Œå¯èƒ½åŒ…å«å¤šç§æ¨¡æ€çš„è¾“å…¥ï¼ˆä¾‹å¦‚ï¼Œå›¾åƒåµŒå…¥ã€æ–‡æœ¬åµŒå…¥ç­‰ï¼‰ã€‚</li>
<li>hidden_states.shape[0]ï¼šè·å–å½“å‰è¾“å…¥æ•°æ®çš„æ‰¹æ¬¡å¤§å°ã€‚</li>
</ul>
<p><strong>ï¼ˆ3ï¼‰è‡ªæ³¨æ„åŠ›ä¸äº¤å‰æ³¨æ„åŠ›</strong></p>
<div class="codehilite"><pre><span></span><code>        <span class="n">num_layers</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_vlm_layers</span>
        <span class="n">head_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">text_config</span><span class="o">.</span><span class="n">head_dim</span>
        <span class="k">for</span> <span class="n">layer_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span>
                <span class="n">fill_kv_cache</span>
                <span class="ow">or</span> <span class="s2">"cross"</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_mode</span>
                <span class="ow">or</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">self_attn_every_n_layers</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">layer_idx</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn_every_n_layers</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">att_outputs</span><span class="p">,</span> <span class="n">past_key_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_attn_layer</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">att_outputs</span><span class="p">,</span> <span class="n">past_key_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_cross_attn_layer</span><span class="p">()</span>
</code></pre></div>
<p>ä½¿ç”¨VLMå±‚æ•°æ¥è¿›è¡Œéå†ï¼Œå› ä¸ºVLMä¾§çš„å±‚æ•°æ˜¯Expertçš„ä¸€å€ã€‚è¿›è¡Œå¦‚å¾ªç¯æ ¹æ®æ¡ä»¶æ¥åˆ¤æ–­æ˜¯è¿›è¡Œè‡ªæ³¨æ„åŠ›è®¡ç®—è¿˜æ˜¯äº¤å‰æ³¨æ„åŠ›è®¡ç®—ã€‚</p>
<p>åˆ¤æ–­ä½¿ç”¨è‡ªæ³¨æ„åŠ›çš„æ¡ä»¶æ˜¯æœ‰3ç§æƒ…å†µï¼ˆå…¶ä¸­ä¸€ç§æ»¡è¶³å³å¯ï¼‰ï¼š</p>
<ul>
<li>fill_kv_cacheï¼šå¦‚æœéœ€è¦å¡«å…… é”®å€¼ç¼“å­˜ï¼ˆkey-value cacheï¼‰ï¼Œåˆ™ä½¿ç”¨è‡ªæ³¨æ„åŠ›è®¡ç®—ã€‚</li>
<li>"cross" not in self.attention_modeï¼šå¦‚æœå½“å‰æ²¡æœ‰å¯ç”¨äº¤å‰æ³¨æ„åŠ›æ¨¡å¼ï¼Œåˆ™ä½¿ç”¨è‡ªæ³¨æ„åŠ›ã€‚</li>
<li>self_attn_every_n_layersï¼šåœ¨æ¯éš” n å±‚è®¡ç®—è‡ªæ³¨æ„åŠ›æ—¶ï¼Œæ‰§è¡Œè¯¥æ¡ä»¶ã€‚é€šå¸¸ç”¨äºå¯ç”¨è·¨å±‚çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ã€‚</li>
</ul>
<p>å…·ä½“å…³äºè‡ªæ³¨æ„åŠ›ä¸äº¤å‰æ³¨æ„åŠ›è®¡ç®—çš„ç»†èŠ‚è§åç»­ç« èŠ‚ã€‚</p>
<p><strong>ï¼ˆ4ï¼‰æ®‹å·®è¿æ¥ä¸å‰é¦ˆç½‘ç»œ</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">out_emb</span> <span class="o">+=</span> <span class="n">hidden_states</span>
<span class="n">after_first_residual</span> <span class="o">=</span> <span class="n">out_emb</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>

<span class="n">out_emb</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">post_attention_layernorm</span><span class="p">(</span><span class="n">out_emb</span><span class="p">)</span>
<span class="n">out_emb</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">out_emb</span><span class="p">)</span>

<span class="n">out_emb</span> <span class="o">+=</span> <span class="n">after_first_residual</span>
</code></pre></div>
<ul>
<li>
<p>æ®‹å·®è¿æ¥ï¼šæ¯ä¸€å±‚éƒ½ä½¿ç”¨æ®‹å·®è¿æ¥ï¼Œå°†å½“å‰å±‚çš„è¾“å‡ºä¸åŸå§‹è¾“å…¥ç›¸åŠ ï¼Œé˜²æ­¢æ·±å±‚ç½‘ç»œçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚</p>
</li>
<li>
<p>å‰é¦ˆç½‘ç»œï¼ˆMLPï¼‰ï¼šé€šè¿‡å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆé€šå¸¸åŒ…æ‹¬ä¸€ä¸ªéšè—å±‚å’Œæ¿€æ´»å‡½æ•°ï¼‰è¿›è¡Œå¤„ç†ï¼Œè¿›ä¸€æ­¥æ•æ‰è¾“å…¥çš„éçº¿æ€§å…³ç³»ã€‚</p>
</li>
</ul>
<p><strong>ï¼ˆ5ï¼‰è¾“å‡ºå¤„ç†</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">outputs_embeds</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">hidden_states</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">hidden_states</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out_emb</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
        <span class="n">outputs_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">out_emb</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">outputs_embeds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
<span class="k">return</span> <span class="n">outputs_embeds</span><span class="p">,</span> <span class="n">past_key_values</span>
</code></pre></div>
<p>éå†è¾“å…¥åµŒå…¥ï¼ˆinputs_embedsï¼‰ï¼Œå¯¹æ¯ä¸ªæœ‰æ•ˆçš„ hidden_states è¿›è¡Œ å½’ä¸€åŒ–å¤„ç†ï¼ˆmodels[i].norm()ï¼‰ã€‚å¦‚æœåµŒå…¥æ— æ•ˆï¼ˆå³ Noneï¼‰ï¼Œåˆ™ç›´æ¥å°† None æ”¾å…¥è¾“å‡ºåˆ—è¡¨ä¸­ï¼Œä»¥ä¿æŒè¾“å…¥ç»“æ„çš„å¯¹é½ã€‚æœ€ç»ˆè¿”å› å¤„ç†åçš„åµŒå…¥ å’Œ past_key_valuesï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ã€‚</p>
<p>å½’ä¸€åŒ–ï¼ˆé€šå¸¸æ˜¯å±‚å½’ä¸€åŒ–ï¼‰ç¡®ä¿åµŒå…¥åœ¨åç»­è®¡ç®—ä¸­å…·æœ‰æ›´å¥½çš„æ•°å€¼ç¨³å®šæ€§ï¼Œå¸®åŠ©æ¨¡å‹å­¦ä¹ ã€‚å¯¹ç¼ºå¤±çš„åµŒå…¥ï¼ˆNoneï¼‰è¿›è¡Œç‰¹æ®Šå¤„ç†ï¼Œä¸»è¦æ˜¯VLM+Expertå¯¹é½æ—¶ï¼ŒExperté€šå¸¸ä¸ºVLMçš„ä¸€åŠï¼Œè€Œæ¨¡å‹éå†æ˜¯æ—¶æŒ‰ç…§VLMå±‚æ¬¡æ¥éå†çš„ï¼Œæ‰€ä»¥æœ‰ä¸€åŠçš„Expertæ˜¯Noneï¼Œä½†æ˜¯è¿™éƒ¨çš„Noneä¸èƒ½åœ¨å¤„ç†VLMå±‚çš„æ—¶å€™æ–­æ‰Expertçš„è¾“å…¥ï¼Œå¦åˆ™Expertæ¨¡å‹æ¢¯åº¦é“¾å°±æ–­äº†ã€‚</p>
<h3 id="_5">æŸå¤±è®¡ç®—</h3>
<div class="codehilite"><pre><span></span><code><span class="n">SmolVLAPolicy</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="o">......</span>
    <span class="n">è°ƒ</span> <span class="n">VLAFlowMatching</span> <span class="n">è®¡ç®—é€æ ·æœ¬</span><span class="o">/</span><span class="n">é€æ­¥</span><span class="o">/</span><span class="n">é€ç»´æŸå¤±</span><span class="err">ï¼ˆ</span><span class="n">ä¸èšåˆ</span><span class="err">ï¼‰</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">img_masks</span><span class="p">,</span> <span class="n">lang_tokens</span><span class="p">,</span> <span class="n">lang_masks</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">actions_is_pad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">in_episode_bound</span> <span class="o">=</span> <span class="o">~</span><span class="n">actions_is_pad</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">losses</span> <span class="o">*</span> <span class="n">in_episode_bound</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1">#  å»æ‰ä¸ºå¯¹é½è€Œpadå‡ºçš„ action ç»´åº¦</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_action_dim</span><span class="p">]</span>

    <span class="c1">#  èšåˆä¸ºæ ‡é‡ lossï¼ˆåå‘ä¼ æ’­ç”¨ï¼‰</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="p">{</span><span class="s2">"loss"</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()}</span>
</code></pre></div>
<p>åœ¨SmolVLAPolicy.forward(...)è°ƒç”¨VLAFlowMatching.forwardè®¡ç®—è¿”å›æŸå¤±ï¼Œä¸‹é¢ç›´æ¥æ¥çœ‹VLAFlowMatching.forwardã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">img_masks</span><span class="p">,</span> <span class="n">lang_tokens</span><span class="p">,</span> <span class="n">lang_masks</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">time</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
    <span class="c1"># â‘  é‡‡æ ·å™ªå£°ä¸æ—¶é—´</span>
    <span class="k">if</span> <span class="n">noise</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_noise</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">actions</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>  <span class="c1"># ~N(0,1)</span>
    <span class="k">if</span> <span class="n">time</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">time</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_time</span><span class="p">(</span><span class="n">actions</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">actions</span><span class="o">.</span><span class="n">device</span><span class="p">)</span> <span class="c1"># Beta(1.5,1.0)â†’åå‘ tâ‰ˆ1</span>

    <span class="c1"># â‘¡ åˆæˆä¸­é—´ç‚¹ x_t ä¸â€œçœŸå‘é‡åœºâ€ u_t</span>
    <span class="n">time_expanded</span> <span class="o">=</span> <span class="n">time</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span>            <span class="c1"># [B,1,1]</span>
    <span class="n">x_t</span> <span class="o">=</span> <span class="n">time_expanded</span> <span class="o">*</span> <span class="n">noise</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">time_expanded</span><span class="p">)</span> <span class="o">*</span> <span class="n">actions</span>    <span class="c1"># convexç»„åˆ</span>
    <span class="n">u_t</span> <span class="o">=</span> <span class="n">noise</span> <span class="o">-</span> <span class="n">actions</span>

    <span class="c1"># â‘¢ å‰ç¼€/åç¼€åµŒå…¥ï¼ˆå›¾åƒ+æ–‡æœ¬+çŠ¶æ€ | åŠ¨ä½œ+æ—¶é—´ï¼‰ï¼Œæ‹¼æ³¨æ„åŠ›mask/ä½ç½®id</span>
    <span class="n">prefix_embs</span><span class="p">,</span> <span class="n">prefix_pad_masks</span><span class="p">,</span> <span class="n">prefix_att_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_prefix</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">img_masks</span><span class="p">,</span> <span class="n">lang_tokens</span><span class="p">,</span> <span class="n">lang_masks</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="n">suffix_embs</span><span class="p">,</span> <span class="n">suffix_pad_masks</span><span class="p">,</span> <span class="n">suffix_att_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_suffix</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>

    <span class="n">pad_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prefix_pad_masks</span><span class="p">,</span> <span class="n">suffix_pad_masks</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">att_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prefix_att_masks</span><span class="p">,</span>  <span class="n">suffix_att_masks</span><span class="p">],</span>  <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">att_2d_masks</span> <span class="o">=</span> <span class="n">make_att_2d_masks</span><span class="p">(</span><span class="n">pad_masks</span><span class="p">,</span> <span class="n">att_masks</span><span class="p">)</span>
    <span class="n">position_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">pad_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="c1"># â‘£ èµ°åŒå¡”æ–‡æœ¬Transformerï¼šprefix + suffixï¼ˆè®­ç»ƒæ—¶ä¸å»ºç¼“å­˜ï¼‰</span>
    <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">suffix_out</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
        <span class="n">attention_mask</span><span class="o">=</span><span class="n">att_2d_masks</span><span class="p">,</span>
        <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
        <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">inputs_embeds</span><span class="o">=</span><span class="p">[</span><span class="n">prefix_embs</span><span class="p">,</span> <span class="n">suffix_embs</span><span class="p">],</span>
        <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">fill_kv_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">suffix_out</span> <span class="o">=</span> <span class="n">suffix_out</span><span class="p">[:,</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">chunk_size</span> <span class="p">:]</span>   <span class="c1"># å–åç¼€å¯¹åº”çš„è¾“å‡ºtoken</span>

    <span class="c1"># â‘¤ Expertå¤´â†’åŠ¨ä½œå‘é‡åœº v_tï¼Œå¹¶ä¸ u_t åšé€å…ƒç´  MSE</span>
    <span class="n">suffix_out</span> <span class="o">=</span> <span class="n">suffix_out</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>         <span class="c1"># æ•°å€¼ç¨³å®š</span>
    <span class="n">v_t</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_out_proj</span><span class="p">(</span><span class="n">suffix_out</span><span class="p">)</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">u_t</span><span class="p">,</span> <span class="n">v_t</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">"none"</span><span class="p">)</span>         <span class="c1"># [B, T, A] ä¸èšåˆ</span>
    <span class="k">return</span> <span class="n">losses</span>
</code></pre></div>
<p>æ ¸å¿ƒæ€æƒ³è¿˜æ˜¯å­¦ä¹ ä¸€ä¸ªå‘é‡åœº $v_{\theta}(x_t,t)$ å»é€¼è¿‘çœŸå®å‘é‡åœº $u_t = \epsilon - a$ï¼Œå…¶ä¸­</p>
<p>$$ x_t = t \cdot \epsilon + (1 - t) \cdot a, \quad \epsilon \sim \mathcal{N}(0,I) $$</p>
<p>$a$ æ˜¯æœºå™¨çœŸå®çš„åŠ¨ä½œå¦‚èˆµæœºçš„è§’åº¦ï¼Œå¯¹åº”ä¸Šè¿°ä»£ç çš„actionï¼›$\epsilon$æ˜¯noisy actionï¼Œæœ€å¼€å§‹éšæœºç”Ÿæˆé‡‡æ ·è€Œæ¥ï¼Œå¯¹åº”ä¸Šè¿°çš„noiseã€‚</p>
<h3 id="_6">æ¨¡å‹å‚æ•°</h3>
<p>æ¨¡å‹å‚æ•°å†»ç»“ä¸»è¦æ˜¯ä»¥ä¸‹ä¸¤ä¸ªæ–¹æ³•å†³å®š</p>
<ul>
<li>SmolVLMWithExpertModel.set_requires_gradï¼ˆç®¡ VLM/Expertçš„å¤§éƒ¨åˆ†å‚æ•°ï¼‰ï¼›</li>
<li>VLAFlowMatching.set_requires_gradï¼ˆåªç®¡ state çš„æŠ•å½±å¤´ï¼‰ã€‚</li>
</ul>
<p><strong>ï¼ˆ1ï¼‰VLM/Expertå¤§éƒ¨åˆ†å‚æ•°</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># 1) å†»ç»“è§†è§‰ç¼–ç å™¨ï¼ˆå¯é€‰ï¼‰</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freeze_vision_encoder</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">get_vlm_model</span><span class="p">()</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_vlm_model</span><span class="p">()</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># 2) åªè®­ç»ƒ Expertï¼ˆå¸¸è§é»˜è®¤ï¼‰</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_expert_only</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vlm</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 3) éâ€œåªè®­ Expertâ€æ—¶ï¼ŒVLM åªå†»ç»“ä¸€å°éƒ¨åˆ†å±‚ï¼Œé¿å… DDP unused params</span>
        <span class="n">last_layers</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">num_vlm_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_vlm_layers</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_expert_layers</span>
            <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_vlm_layers</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_expert_layers</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">last_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_vlm_layers</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span>

        <span class="n">frozen</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"lm_head"</span><span class="p">,</span> <span class="s2">"text_model.model.norm.weight"</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">L</span> <span class="ow">in</span> <span class="n">last_layers</span><span class="p">:</span>
            <span class="n">frozen</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">"text_model.model.layers.</span><span class="si">{</span><span class="n">L</span><span class="si">}</span><span class="s2">."</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">k</span> <span class="ow">in</span> <span class="n">name</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">frozen</span><span class="p">):</span>
                <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># 4) Expert ä¾§ä¸è®­ç»ƒ lm_headï¼ˆæ²¡ç”¨åˆ° LM å¤´ï¼‰</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm_expert</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="k">if</span> <span class="s2">"lm_head"</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</code></pre></div>
<ul>
<li>å†»ç»“è§†è§‰ç¼–ç å™¨ï¼šæŠŠ VLM çš„ vision encoder åˆ‡åˆ° eval()ï¼Œå¹¶æŠŠå…¶æ‰€æœ‰å‚æ•° requires_grad=Falseã€‚å¯¹äºVLMè§†è§‰éƒ¨åˆ†å·²ç»æ¯”è¾ƒç¨³å®šäº†ï¼Œè‹¥ä¸‹æ¸¸æ•°æ®é‡ä¸å¤§ï¼Œç»§ç»­è®­ç»ƒæ˜“å¸¦æ¥ä¸ç¨³å®šä¸æ˜¾å­˜å¼€é”€ï¼›å†»ç»“èƒ½çœèµ„æºå¹¶ä¿æŒè§†è§‰è¡¨å¾ç¨³å®šã€‚</li>
<li>åªè®­ç»ƒ Expertï¼šæŠŠVLMçš„ï¼ˆè§†è§‰ç¼–ç +LLMï¼‰éƒ½èµ·åˆ°evalä¸”å…¨éƒ¨å†»ç»“ã€‚è¿™æ˜¯ä¸€ç§è½»é‡å¾®è°ƒç­–ç•¥â€”â€”åªè®­ç»ƒ Expert+ åŠ¨ä½œ/æ—¶é—´/çŠ¶æ€æŠ•å½±å¤´ï¼Œèƒ½åœ¨å°æ•°æ®ä¸Šå¿«é€Ÿç¨³å®šæ”¶æ•›ï¼Œé¿å…å¯¹å¤§æ¨¡å‹è¯­ä¹‰åˆ†å¸ƒé€ æˆç ´åã€‚</li>
<li>éâ€œåªè®­ Expertâ€æ—¶ï¼ŒVLM åªå†»ç»“ä¸€å°éƒ¨åˆ†å±‚ï¼šæ°¸è¿œå†»ç»“ VLM çš„ lm_headï¼ˆè¯­è¨€æ¨¡å‹å¤´ï¼ŒåŠ¨ä½œä»»åŠ¡ç”¨ä¸åˆ°ï¼‰ï¼Œå†»ç»“text_model.model.norm.weightï¼Œé™ä½è®­ç»ƒä¸ç¨³å®šï¼Œå†»ç»“æœ€å 1 å±‚ï¼›</li>
</ul>
<p>æ€»ç»“ä¸€ä¸‹ï¼š</p>
<table>
<thead>
<tr>
<th>ç›®æ ‡</th>
<th>å…¸å‹è®¾ç½®</th>
<th>å®é™…å¯è®­ç»ƒéƒ¨åˆ†</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>è½»é‡å¾®è°ƒï¼ˆé»˜è®¤/æ¨èèµ·æ­¥ï¼‰</strong></td>
<td>freeze_vision_encoder=True + train_expert_only=True</td>
<td><strong>Expert å…¨éƒ¨å±‚ï¼ˆé™¤ lm_headï¼‰</strong> + <strong>åŠ¨ä½œ/æ—¶é—´/çŠ¶æ€å¤´</strong>ï¼ˆVLAFlowMatching é‡Œçš„ action_in/out_projã€action_time_mlp_ã€state_projï¼‰</td>
</tr>
<tr>
<td><strong>åŠ å¼ºè¡¨è¾¾ï¼ˆéƒ¨åˆ†æ”¾å¼€ VLMï¼‰</strong></td>
<td>freeze_vision_encoder=True/False + train_expert_only=False</td>
<td><strong>Expert å…¨éƒ¨å±‚</strong> + <strong>å¤§å¤šæ•° VLM æ–‡æœ¬å±‚</strong>ï¼ˆä½†å†»ç»“ lm_headã€æœ«å°¾ normã€æœ€å 1â€“2 å±‚ï¼‰ + <strong>åŠ¨ä½œ/æ—¶é—´/çŠ¶æ€å¤´</strong></td>
</tr>
</tbody>
</table>
<p>é™¤äº†ä¸Šé¢çš„å‚æ•°ä¹‹å¤–åœ¨ SmolVLMWithExpertModel.train ä¸­åˆåšäº†ä¸€å±‚ä¿é™©ï¼š</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">mode</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">freeze_vision_encoder</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">get_vlm_model</span><span class="p">()</span><span class="o">.</span><span class="n">vision_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_expert_only</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vlm</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</code></pre></div>
<p>å³ä½¿å¤–éƒ¨è°ƒç”¨äº† model.train()ï¼Œè¢«å†»çš„æ¨¡å—ä»ä¿æŒ eval()ï¼Œé¿å… Dropout/BN ç­‰è®­ç»ƒæ€è¡Œä¸ºå¹²æ‰°ã€‚æ˜¯å¦å‚ä¸åå‘ä»ç”± requires_grad å†³å®šï¼›ä¸¤è€…é…åˆä¿è¯â€œçœŸå†»ç»“â€ã€‚</p>
<p><strong>ï¼ˆ2ï¼‰state çš„æŠ•å½±å¤´</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">VLAFlowMatching</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span> <span class="o">=</span> <span class="n">SmolVLMWithExpertModel</span><span class="p">(</span> <span class="o">...</span> <span class="p">)</span>

        <span class="c1"># â€”â€” ä¸åŠ¨ä½œ/çŠ¶æ€/æ—¶é—´ç›¸å…³çš„æŠ•å½±å¤´ â€”â€” </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">state_proj</span>        <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_state_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">text_config</span><span class="o">.</span><span class="n">hidden_size</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_in_proj</span>    <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_action_dim</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">expert_hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_out_proj</span>   <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">expert_hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">max_action_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_time_mlp_in</span>  <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">expert_hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">expert_hidden_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_time_mlp_out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">expert_hidden_size</span><span class="p">,</span>     <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">expert_hidden_size</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_requires_grad</span><span class="p">()</span>   <span class="c1"># â† è¿™é‡Œè°ƒç”¨</span>

        <span class="o">...</span>
    <span class="k">def</span> <span class="nf">set_requires_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">state_proj</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">params</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">train_state_proj</span>
</code></pre></div>
<p>æ ¹æ® config.train_state_projï¼ˆå¸ƒå°”å€¼ï¼‰å¼€/å…³çŠ¶æ€æŠ•å½±å±‚ state_proj çš„å¯è®­ç»ƒæ€§ã€‚è¿™é‡Œåªå¯¹state_projåšæ§åˆ¶ï¼Œè¿™ä¸ªæ˜¯æŠŠæœºå™¨äººçŠ¶æ€ï¼ˆå…³èŠ‚è§’ã€æŠ“å–å¼€åˆç­‰ï¼‰æ˜ å°„åˆ° VLM æ–‡æœ¬ç¼–ç å™¨çš„éšè—ç»´åº¦ã€‚ä¸åŒæœºå™¨äºº/ä»»åŠ¡ï¼ŒçŠ¶æ€åˆ†å¸ƒå·®å¼‚å¾ˆå¤§ï¼ˆé‡çº²ã€èŒƒå›´ã€ç›¸å…³æ€§ï¼‰ï¼›æ˜¯å¦éœ€è¦å­¦ä¹ è¿™ä¸ªæ˜ å°„ï¼Œå–å†³äºä½ çš„æ•°æ®è§„æ¨¡ä¸åˆ†å¸ƒï¼Œæ‰€ä»¥å¯ä»¥æ ¹æ®train_state_proj=True/Falseæ¥å†³å®šæ˜¯å¦è¦è®­ç»ƒæˆ–å†»ç»“ã€‚å…¶å®ƒå¤´ï¼ˆaction_in/out_projã€action_time_mlp_*ï¼‰å¯¹åŠ¨ä½œ/æ—¶é—´æ›´ç›´æ¥ï¼Œé€šå¸¸éƒ½éœ€è¦å­¦ä¹ ï¼Œå› æ­¤é»˜è®¤ä¸åœ¨è¿™é‡Œå†»ç»“ã€‚</p>
<h2 id="_7">æ¨ç†</h2>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/08/wp_editor_md_cfbb8d30a3b9ab1ff705563b848f2051_1756286500.png"><img alt="" src="assets/doc/04-ai/lerobot/lerobot-smolvlaç­–ç•¥/images/wp_editor_md_cfbb8d30a3b9ab1ff705563b848f2051_1756286500.png"/></a></p>
<p>æ¨ç†çš„å…¥å£å‡½æ•°å…¥å£ï¼šSmolVLAPolicy.predict_action_chunk -&gt;select_action-&gt; VLAFlowMatching.sample_actions(...)ï¼Œæ¨ç†è·Ÿè®­ç»ƒæµç¨‹å¤§è‡´ç›¸åŒï¼Œè¿™é‡Œåªç®€å•æ€»ç»“ä¸€ä¸‹ä¸åŒç‚¹ã€‚</p>
<h3 id="_8">å‰ç¼€ç¼“å­˜</h3>
<div class="codehilite"><pre><span></span><code><span class="n">prefix_embs</span><span class="p">,</span> <span class="n">prefix_pad_masks</span><span class="p">,</span> <span class="n">prefix_att_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_prefix</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">prefix_att_2d_masks</span> <span class="o">=</span> <span class="n">make_att_2d_masks</span><span class="p">(</span><span class="n">prefix_pad_masks</span><span class="p">,</span> <span class="n">prefix_att_masks</span><span class="p">)</span>
<span class="n">prefix_position_ids</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">prefix_pad_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

<span class="c1"># åªå–‚å‰ç¼€ï¼Œæ„å»º KV cache</span>
<span class="n">_</span><span class="p">,</span> <span class="n">past_key_values</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">prefix_att_2d_masks</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="o">=</span><span class="n">prefix_position_ids</span><span class="p">,</span>
    <span class="n">past_key_values</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">inputs_embeds</span><span class="o">=</span><span class="p">[</span><span class="n">prefix_embs</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>   <span class="c1"># â˜… åªæœ‰å‰ç¼€</span>
    <span class="n">use_cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span><span class="p">,</span>     <span class="c1"># é€šå¸¸ True</span>
    <span class="n">fill_kv_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>                  <span class="c1"># â˜… å»ºç¼“å­˜</span>
<span class="p">)</span>
</code></pre></div>
<p>ä¸è®­ç»ƒçš„å·®åˆ«æ˜¯è®­ç»ƒä¸å»ºç¼“å­˜ï¼Œæ¨ç†å…ˆæŠŠ VLM çš„ Q/K/Vï¼ˆæ›´å‡†ç¡®ï¼šK/Vï¼‰ç®—å‡ºæ¥å¹¶å­˜èµ·æ¥ï¼ˆpast_key_valuesï¼‰ï¼Œè¿™æ­¥åªèµ° self-attn åˆ†æ”¯ï¼ˆå› ä¸º fill_kv_cache=Trueï¼‰ï¼ŒExpert ä¸å‚ä¸ã€‚å¦å¤–éœ€è¦æ³¨æ„çš„æ—¶ä¼ é€’çš„è¾“å…¥åªæœ‰prefix_embsè€Œè®­ç»ƒæ˜¯inputs_embeds=[prefix_embs, suffix_embs]æ—¢è¦ä¼ é€’prefix_embsä¹Ÿæœ‰ä¼ é€’suffix_embsï¼Œè¿™é‡Œçš„åç¼€ç¼–ç ä¸ºæ’å€¼ç‚¹çš„åµŒå…¥ï¼Œå³x_t = time_expanded * noise + (1 - time_expanded) * actionsã€‚å› ä¸ºæ²¡æœ‰Expertçš„è¾“å…¥ï¼Œæ‰€ä»¥è‡ªæ³¨æ„åŠ›ç®—çš„ä¹Ÿåªæœ‰VLMçš„è¾“å…¥ã€‚</p>
<h3 id="_9">åç¼€å¾ªç¯</h3>
<div class="codehilite"><pre><span></span><code><span class="n">dt</span>   <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">num_steps</span>
<span class="n">x_t</span>  <span class="o">=</span> <span class="n">noise</span>  <span class="c1"># åˆå§‹å™ªå£°</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="k">while</span> <span class="n">time</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="n">dt</span><span class="o">/</span><span class="mi">2</span><span class="p">:</span>
    <span class="n">v_t</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">denoise_step</span><span class="p">(</span><span class="n">prefix_pad_masks</span><span class="p">,</span> <span class="n">past_key_values</span><span class="p">,</span> <span class="n">x_t</span><span class="p">,</span> <span class="n">time</span><span class="p">)</span>
    <span class="n">x_t</span> <span class="o">+=</span> <span class="n">dt</span> <span class="o">*</span> <span class="n">v_t</span>   <span class="c1"># Euler æ›´æ–°</span>
    <span class="n">time</span> <span class="o">+=</span> <span class="n">dt</span>
<span class="k">return</span> <span class="n">x_t</span>  <span class="c1"># ä½œä¸ºåŠ¨ä½œ</span>
</code></pre></div>
<p>åš ODE å»å™ªå¾ªç¯ï¼ˆEulerï¼‰ï¼Œæ¯ä¸€æ­¥åªç®—åç¼€ã€‚ä¸è®­ç»ƒçš„å·®åˆ«æ˜¯â€œé‡‡ä¸€ä¸ªéšæœº t ç›´æ¥ç›‘ç£å‘é‡åœºâ€ï¼Œæ¨ç†æ˜¯â€œä» t=1 ç§¯åˆ†åˆ° t=0â€ï¼ˆODE è§£ï¼‰ã€‚è¿™é‡Œçš„ num_steps æ§åˆ¶ç§¯åˆ†æ­¥æ•°ï¼ˆç²¾åº¦/é€Ÿåº¦æƒè¡¡ï¼‰ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="n">denoise_step</span><span class="p">(</span><span class="o">...</span><span class="p">)</span><span class="o">----&gt;</span>

<span class="n">suffix_embs</span><span class="p">,</span> <span class="n">suffix_pad_masks</span><span class="p">,</span> <span class="n">suffix_att_masks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed_suffix</span><span class="p">(</span><span class="n">x_t</span><span class="p">,</span> <span class="n">timestep</span><span class="p">)</span>
<span class="c1"># ç»„è£… prefix/suffix çš„è”åˆæ³¨æ„åŠ›æ©ç ï¼ˆprefix åªæä¾› pad_2d ä»¥å…è®¸è¢«çœ‹ï¼‰</span>
<span class="n">full_att_2d_masks</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prefix_pad_2d_masks</span><span class="p">,</span> <span class="n">suffix_att_2d_masks</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">position_ids</span> <span class="o">=</span> <span class="n">prefix_offsets</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">suffix_pad_masks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>

<span class="n">outputs_embeds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vlm_with_expert</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">full_att_2d_masks</span><span class="p">,</span>
    <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
    <span class="n">past_key_values</span><span class="o">=</span><span class="n">past_key_values</span><span class="p">,</span>  <span class="c1"># â˜… å¤ç”¨ prefix KV</span>
    <span class="n">inputs_embeds</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">suffix_embs</span><span class="p">],</span><span class="c1"># â˜… åªæœ‰åç¼€</span>
    <span class="n">use_cache</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span><span class="p">,</span>  <span class="c1"># True</span>
    <span class="n">fill_kv_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>              <span class="c1"># â˜… ä¸å†å»ºç¼“å­˜</span>
<span class="p">)</span>
<span class="n">suffix_out</span> <span class="o">=</span> <span class="n">outputs_embeds</span><span class="p">[</span><span class="mi">1</span><span class="p">][:,</span> <span class="o">-</span><span class="n">chunk_size</span><span class="p">:]</span>
<span class="n">v_t</span>        <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_out_proj</span><span class="p">(</span><span class="n">suffix_out</span><span class="p">)</span>
</code></pre></div>
<p>denoise_step(...)æ‹¿ç¼“å­˜ + <strong>åªå–‚åç¼€ï¼ˆå‰ç¼€ä¸ºNoneï¼‰</strong>ï¼Œåˆ†å±‚èµ° cross/selfã€‚VLM ä¸å†é‡ç®— Q/K/Vï¼Œå±‚å†… cross-attn æ—¶ï¼ŒExpert çš„ Query å»çœ‹ prefix çš„ K/V ç¼“å­˜ï¼›è‹¥è¯¥å±‚è¢« self_attn_every_n_layers å¼ºåˆ¶ selfï¼Œåˆ™åªåš Expert è‡ªæ³¨æ„ï¼ˆVLM æ—è·¯ï¼Œå› ä¸ºæ²¡æœ‰è¾“å…¥å‰ç¼€ï¼‰ã€‚ä¸è®­ç»ƒçš„å·®åˆ«æ˜¯è®­ç»ƒæ—¶ä¸¤ä¾§ä¸€èµ·ç®—ï¼ˆinputs_embeds=[prefix, suffix]ï¼‰ï¼Œä¸”æ— ç¼“å­˜ã€‚</p>
<p><strong>è®­ç»ƒ vs æ¨ç†</strong></p>
<table>
<thead>
<tr>
<th>ç»´åº¦</th>
<th>è®­ç»ƒï¼ˆVLAFlowMatching.forwardï¼‰</th>
<th>æ¨ç†ï¼ˆsample_actions + denoise_stepï¼‰</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>æ˜¯å¦ç”¨çœŸåŠ¨ä½œ</strong></td>
<td>ç”¨ï¼Œå‚ä¸æ„é€  x_t,t ä¸ u_t=noise-actionsï¼Œå½¢æˆç›‘ç£</td>
<td>ä¸ç”¨ï¼ˆæ²¡æœ‰ labelï¼‰ï¼Œä»å™ªå£°è§£ ODE å¾—åŠ¨ä½œ</td>
</tr>
<tr>
<td><strong>æ—¶é—´ä½¿ç”¨</strong></td>
<td>éšæœºé‡‡æ · t~Beta(1.5,1.0)ï¼Œå•æ­¥ç›‘ç£</td>
<td>ä» t=1 åˆ° t=0 è¿­ä»£ï¼ˆæ­¥é•¿ dt=-1/num_stepsï¼‰</td>
</tr>
<tr>
<td><strong>æ˜¯å¦å»º KV Cache</strong></td>
<td>å¦ï¼ˆuse_cache=False, fill_kv_cache=Falseï¼‰</td>
<td>æ˜¯ï¼šå…ˆ<strong>prefix-only</strong> å»ºç¼“å­˜ï¼›å¾ªç¯ä¸­ <strong>suffix-only</strong> å¤ç”¨ç¼“å­˜</td>
</tr>
<tr>
<td><strong>ä¸¤å¡”å‰å‘å–‚æ³•</strong></td>
<td>ä¸€æ¬¡æ€§ inputs_embeds=[prefix, suffix]</td>
<td>ä¸¤æ®µï¼šâ‘  [prefix, None]ï¼ˆå»ºç¼“å­˜ï¼‰ï¼›â‘¡ [None, suffix]ï¼ˆå¤ç”¨ç¼“å­˜ï¼‰</td>
</tr>
<tr>
<td><strong>å±‚å†…æ³¨æ„åŠ›è·¯ç”±</strong></td>
<td>ç”± attention_mode / self_attn_every_n_layers å†³å®šï¼Œä½†æ— ç¼“å­˜ä¸Šä¸‹æ–‡</td>
<td>ç›¸åŒè·¯ç”±ï¼›<strong>cross æ—¶ Expert-Q Ã— cached VLM-KV</strong>ï¼›self æ—¶åª Expert è‡ªæ³¨æ„</td>
</tr>
<tr>
<td><strong>ä½ç½®ç¼–ç ï¼ˆRoPEï¼‰</strong></td>
<td>æ¯å±‚å¯¹å‚ä¸è®¡ç®—çš„ Q/K åº”ç”¨</td>
<td>åŒä¸Šï¼›prefix çš„ä½ç½®åœ¨å»ºç¼“å­˜æ—¶ç”¨è¿‡ï¼›suffix åœ¨æ¯æ­¥éƒ½é‡ç®—</td>
</tr>
<tr>
<td><strong>æŸå¤±/æ¢¯åº¦</strong></td>
<td>MSE(u_t, v_t) â†’ åå‘</td>
<td>æ— æŸå¤±ã€æ— åå‘</td>
</tr>
<tr>
<td><strong>è¾“å‡ºåå¤„ç†</strong></td>
<td>è¿”å›æ ‡é‡ lossï¼ˆpolicy ä¸­èšåˆ/æ©ç åï¼‰</td>
<td>x_t ä½œä¸ºåŠ¨ä½œ â†’ unnormalize â†’ï¼ˆå¯é€‰ï¼‰Aloha æ˜ å°„ï¼›æ”¯æŒ n-step é˜Ÿåˆ—</td>
</tr>
</tbody>
</table>
<h2 id="_10">æ³¨æ„åŠ›</h2>
<p>æ³¨æ„åŠ›çš„è®¡ç®—æ˜¯æ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„æ ¸å¿ƒï¼Œä¸»è¦æ¶‰åŠè‡ªæ³¨æ„åŠ›å’Œäº¤å‰æ³¨æ„åŠ›ï¼Œè¿™é‡Œå•ç‹¬æ€»ç»“ä¸€ç« èŠ‚è¿›è¡Œæ¢³ç†åˆ†æã€‚</p>
<h3 id="_11">è‡ªæ³¨æ„åŠ›</h3>
<p>è‡ªæ³¨æ„åŠ›çš„ä»£ç æ³¨æ„åœ¨forward_attn_layerå‡½æ•°ä¸­ï¼Œæ¥ä¸‹æ¥æ ¹æ®ä»£ç æ¥è¿›è¡Œåˆ†æã€‚</p>
<p><strong>ï¼ˆ1ï¼‰è‡ªæ³¨æ„åŠ›QKVè®¡ç®—</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">query_states</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">key_states</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">value_states</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div>
<p>é¦–å…ˆå®šä¹‰äº†Self-Attention ä¸­çš„ Queryã€Key å’Œ Valueã€‚è¿™äº›å°†ç”¨äºè®¡ç®—æ³¨æ„åŠ›æƒé‡ã€‚</p>
<div class="codehilite"><pre><span></span><code>        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">hidden_states</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="p">):</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="n">model_layers</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">layer_idx</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">hidden_states</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">layer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">input_layernorm</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span>
</code></pre></div>
<p>inputs_embeds æ˜¯ä¸€ä¸ªåŒ…å«ä¸åŒæ¨¡æ€è¾“å…¥çš„åˆ—è¡¨æˆ–å¼ é‡ã€‚ä¾‹å¦‚ï¼Œå®ƒå¯èƒ½åŒ…å« VLM çš„å‰ç¼€è¾“å…¥ï¼ˆå›¾åƒã€æ–‡æœ¬ã€çŠ¶æ€ï¼‰å’Œ Expert çš„åç¼€è¾“å…¥ï¼ˆåŠ¨ä½œã€æ—¶é—´ï¼‰ã€‚enumerate(inputs_embeds) ä¼šéå† inputs_embeds ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œå¹¶è¿”å› iï¼ˆå½“å‰å…ƒç´ çš„ç´¢å¼•ï¼‰å’Œ hidden_statesï¼ˆå¯¹åº”çš„è¾“å…¥åµŒå…¥ï¼‰ã€‚é€šè¿‡ enumerate æˆ‘ä»¬å¯ä»¥åˆ†åˆ«å¤„ç†æ¯ä¸ªè¾“å…¥æ¨¡æ€ï¼Œi ç”¨æ¥åŒºåˆ†æ˜¯å¤„ç† VLM è¿˜æ˜¯ Expertã€‚i=0 å¯¹åº” VLM çš„è¾“å…¥ï¼Œi=1 å¯¹åº” Expert çš„è¾“å…¥ã€‚</p>
<p>å› æ­¤model_layers[i][layer_idx]æ ¹æ® i æ¥é€‰æ‹©å½“å‰æ˜¯å¤„ç† VLM å±‚è¿˜æ˜¯ Expert å±‚ã€‚å¦‚æœ i=0ï¼Œåˆ™é€‰æ‹© VLM çš„å±‚ï¼›å¦‚æœ i=1ï¼Œåˆ™é€‰æ‹© Expert çš„å±‚ã€‚layer_idxæ˜¯å½“å‰å¤„ç†çš„å±‚çš„ç´¢å¼•ï¼ŒæŒ‡å®šå½“å‰æ¨¡å‹ä¸­çš„å“ªä¸€å±‚è¿›è¡Œå¤„ç†ã€‚</p>
<p>å½“åˆ¤æ–­hidden_states is Noneæˆ–layer is Noneæ˜¯åˆ™è·³è¿‡ä¸å¤„ç†ï¼Œå¯¹äºExpertä¾§æ¥è¯´ä¼šä¸ºç©ºï¼Œå› ä¸ºå¤–å±‚æ˜¯æŒ‰ç…§VLMå±‚æ•°æ¥éå†çš„ï¼ŒExpertåªæœ‰VLMçš„ä¸€åŠï¼Œå› æ­¤æ¯éš”VLMä¸€å±‚å°±ä¼šæœ‰ä¸€ä¸ªExpertä¸ºç©ºã€‚</p>
<p>å…ˆä½¿ç”¨input_layernormå¯¹å½“å‰è¾“å…¥hidden_statesè¿›è¡Œå½’ä¸€åŒ–ã€‚ç„¶åå°±å„è‡ªè¿›è¡ŒQ/K/Vè®¡ç®—ã€‚</p>
<div class="codehilite"><pre><span></span><code>            <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">hidden_states</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">q_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">query_state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">q_proj</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">hidden_shape</span><span class="p">)</span>
            <span class="n">key_state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">k_proj</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">hidden_shape</span><span class="p">)</span>
            <span class="n">value_state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">v_proj</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">hidden_shape</span><span class="p">)</span>

            <span class="n">query_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">query_state</span><span class="p">)</span>
            <span class="n">key_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key_state</span><span class="p">)</span>
            <span class="n">value_states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value_state</span><span class="p">)</span>
</code></pre></div>
<p>åœ¨forå¾ªç¯ä¸­ï¼Œéå†VLMå’ŒExpertå„è‡ªè®¡ç®—Q/K/Vï¼Œç„¶åæŠŠVLMå’ŒExpertè®¡ç®—çš„Q/K/Véƒ½åˆ†ç±»å„è‡ªåŠ å…¥åˆ°ç›¸åŒçš„åˆ—è¡¨ä¸­ï¼Œå¦‚VLMå’ŒExpertçš„QåŠ å…¥åˆ—è¡¨query_states.appendã€‚</p>
<p><strong>ï¼ˆ2ï¼‰æ‹¼æ¥QKV</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">query_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">query_states</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">key_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">key_states</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">value_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">value_states</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p>å°†VLMå’ŒExpertè®¡ç®—å‡ºæ¥çš„Queryã€Keyã€Valueå„è‡ªæ‹¼æ¥æˆä¸€ä¸ªå¤§çš„å¼ é‡ï¼Œç”¨äºåç»­çš„æ³¨æ„åŠ›è®¡ç®—ï¼Œä»è¿™é‡Œå¯ä»¥çœ‹å‡ºã€‚VLMå’ŒExpertçš„æ³¨æ„åŠ›è®¡ç®—æ˜¯ä½¿ç”¨ä¸€ä¸ªtransformeråŒæ—¶å¯¹VLM+Expertçš„è¾“å…¥æ‹¼æ¥è¾“å…¥è®¡ç®—çš„ã€‚ç›¸å½“äºVLMå’ŒExpertçš„è¾“å…¥å¯ä»¥åŒå‘æ³¨æ„åŠ›ã€‚</p>
<p><strong>ï¼ˆ3ï¼‰EoPEç¼–ç </strong></p>
<div class="codehilite"><pre><span></span><code>        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">query_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">seq_len</span> <span class="o">&lt;</span> <span class="n">position_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">_position_ids</span> <span class="o">=</span> <span class="n">position_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">]</span>
            <span class="n">_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_position_ids</span> <span class="o">=</span> <span class="n">position_ids</span>
            <span class="n">_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span>

        <span class="n">attention_mask_</span> <span class="o">=</span> <span class="n">_attention_mask</span>
        <span class="n">position_ids_</span> <span class="o">=</span> <span class="n">_position_ids</span>

        <span class="n">query_states</span> <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">query_states</span><span class="p">,</span> <span class="n">position_ids_</span><span class="p">)</span>
        <span class="n">key_states</span> <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">key_states</span><span class="p">,</span> <span class="n">position_ids_</span><span class="p">)</span>
</code></pre></div>
<p>è¿™æ®µä»£ç ä¸»è¦å¤„ç†çš„æ˜¯ä½ç½®ç¼–ç å’Œæ³¨æ„åŠ›æ©ç ï¼Œè¿™é‡Œä¸»è¦æ˜¯å¼•å…¥äº†RoPEç¼–ç ï¼Œè®¡ç®—ä¸¤ä¸ªä½ç½®ä¹‹é—´çš„ç›¸å¯¹è·ç¦»æ¥æ„é€ ç¼–ç ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºç»å¯¹ä½ç½®ï¼Œæé«˜å¢å¼ºæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
<p><strong>ï¼ˆ4ï¼‰ç¼“å­˜æœºåˆ¶</strong></p>
<div class="codehilite"><pre><span></span><code>      <span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">fill_kv_cache</span><span class="p">:</span>
                <span class="n">past_key_values</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s2">"key_states"</span><span class="p">:</span> <span class="n">key_states</span><span class="p">,</span>
                    <span class="s2">"value_states"</span><span class="p">:</span> <span class="n">value_states</span><span class="p">,</span>
                <span class="p">}</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># TODO here, some optimization can be done - similar to a `StaticCache` we can declare the `max_len` before.</span>
                <span class="c1"># so we create an empty cache, with just one cuda malloc, and if (in autoregressive case) we reach</span>
                <span class="c1"># the max len, then we (for instance) double the cache size. This implementation already exists</span>
                <span class="c1"># in `transformers`. (molbap)</span>
                <span class="n">key_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">past_key_values</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">][</span><span class="s2">"key_states"</span><span class="p">],</span> <span class="n">key_states</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">value_states</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">past_key_values</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">][</span><span class="s2">"value_states"</span><span class="p">],</span> <span class="n">value_states</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p>å°†æ¯ä¸€å±‚çš„Keyå’ŒValueç¼“å­˜åˆ°<strong>past_key_values</strong>[layer_idx]ä¸­ï¼Œæ¨¡å‹è®­ç»ƒæ—¶è¿™é‡Œçš„use_cacheè®¾ç½®ä¸º0ï¼Œå½“æ¨¡å‹æ˜¯æ¨ç†æ—¶use_cacheè®¾ç½®ä¸º1ï¼Œfill_kv_cacheè®¾ç½®ä¸º1ã€‚ä¸»è¦æ˜¯åœ¨æ¨ç†é˜¶æ®µï¼Œä¼šå…ˆè°ƒç”¨VLM+Expertæ¨¡å‹æ¨ç†ä¸€æ¬¡å°†Keyã€Valueè¿›è¡Œç¼“å­˜ä¿å­˜èµ·æ¥ï¼Œåç»­å°±åªæ˜¯æ¨ç†Expertäº†ï¼ŒVLMå°†ä¸å†è®¡ç®—äº†ï¼Œé€šè¿‡è¿™æ ·çš„æ–¹å¼ä»¥æé«˜è®¡ç®—æ•ˆç‡ã€‚</p>
<p><strong>ï¼ˆ5ï¼‰æ³¨æ„åŠ›è¾“å‡º</strong></p>
<div class="codehilite"><pre><span></span><code>        <span class="n">att_output</span> <span class="o">=</span> <span class="n">attention_interface</span><span class="p">(</span>
            <span class="n">attention_mask_</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">,</span> <span class="n">query_states</span><span class="p">,</span> <span class="n">key_states</span><span class="p">,</span> <span class="n">value_states</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">att_output</span><span class="p">],</span> <span class="n">past_key_values</span>
</code></pre></div>
<p>æ³¨æ„åŠ›è®¡ç®—æ—¶ä¼šæŠŠå¯ç”¨æ¥æºï¼ˆVLM å‰ç¼€ã€Expert åç¼€ï¼‰å„è‡ªç®—å‡ºçš„ Q/K/Våœ¨åºåˆ—ç»´åº¦æ‹¼æ¥åç»Ÿä¸€åšä¸€æ¬¡æ³¨æ„åŠ›ï¼Œä½†æ©ç ä¿è¯äº†â€œå•å‘å¯è§â€ï¼Œå³<strong>VLM ä¸ Expert çš„ Q/K/Véƒ½å‚ä¸æ‹¼æ¥ï¼Œä½†äºŒç»´æ©ç ä½¿ VLM åŸºæœ¬ä¸çœ‹ Expertï¼ŒExpert èƒ½çœ‹ VLM</strong>ã€‚</p>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/08/wp_editor_md_2b960016ce1221f88389b36f18a972a9_1756288204.png"><img alt="" src="assets/doc/04-ai/lerobot/lerobot-smolvlaç­–ç•¥/images/wp_editor_md_2b960016ce1221f88389b36f18a972a9_1756288204.png"/></a></p>
<h3 id="_12">äº¤å‰æ³¨æ„åŠ›</h3>
<p>äº¤å‰æ³¨æ„åŠ›åœ¨forward_cross_attn_layerä¸­å®ç°ã€‚ä¸‹é¢æ¥è¿›è¡Œåˆ†æã€‚</p>
<p><strong>ï¼ˆ1ï¼‰å‰ç¼€è‡ªæ³¨æ„åŠ›</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">past_key_values</span><span class="p">:</span>
    <span class="n">seq_len</span> <span class="o">=</span> <span class="n">inputs_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">position_id</span><span class="p">,</span> <span class="n">expert_position_id</span> <span class="o">=</span> <span class="n">position_ids</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">],</span> <span class="n">position_ids</span><span class="p">[:,</span> <span class="n">seq_len</span><span class="p">:]</span>
    <span class="n">prefix_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">,</span> <span class="p">:</span><span class="n">seq_len</span><span class="p">]</span>

    <span class="n">layer</span> <span class="o">=</span> <span class="n">model_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">layer_idx</span><span class="p">]</span>          <span class="c1"># é€‰ VLM çš„ç¬¬ layer_idx å±‚</span>
    <span class="n">hidden_states</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">input_layernorm</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># æŠ•å½±å‡º VLM çš„ Q/K/V</span>
    <span class="n">query_state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">q_proj</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">Lp</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">Dh</span><span class="p">)</span>
    <span class="n">key_state</span>   <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">k_proj</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">Lp</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">Dh</span><span class="p">)</span>
    <span class="n">value_state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">v_proj</span><span class="p">(</span><span class="n">hidden_states</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">Lp</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">Dh</span><span class="p">)</span>

    <span class="c1"># å¯¹ Q/K æ–½åŠ  RoPEï¼ˆç›¸å¯¹ä½ç½®ç¼–ç ï¼‰</span>
    <span class="n">query_states</span> <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">query_state</span><span class="p">,</span> <span class="n">position_id</span><span class="p">)</span>
    <span class="n">key_states</span>   <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">key_state</span><span class="p">,</span>   <span class="n">position_id</span><span class="p">)</span>

    <span class="c1"># åªåœ¨ prefix ä¸Šè‡ªæ³¨æ„åŠ›ï¼ˆç”¨ prefix çš„æ–¹é˜µ maskï¼‰</span>
    <span class="n">att_output</span> <span class="o">=</span> <span class="n">attention_interface</span><span class="p">(</span><span class="n">prefix_attention_mask</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">,</span>
                                     <span class="n">query_states</span><span class="p">,</span> <span class="n">key_states</span><span class="p">,</span> <span class="n">value_state</span><span class="p">)</span>
    <span class="n">att_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">att_output</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">expert_position_id</span> <span class="o">=</span> <span class="n">position_ids</span>
</code></pre></div>
<p>å½“æ»¡è¶³inputs_embedsæœ‰å‰ç¼€+åç¼€çš„æ•°æ®ä¸”æ²¡æœ‰ç¼“å­˜çš„æ—¶ï¼Œåªå–VLMçš„è¾“å…¥prefixç”¨äºè®¡ç®—è‡ªæ³¨æ„åŠ›ï¼Œè¾“å‡ºç»“æœä¸ºatt_outputsã€‚åŒæ—¶å¦‚æœè¿™å±‚æ˜¯Expertçš„äº¤å‰æ³¨æ„åŠ›ï¼Œé‚£ä¹ˆVLMè®¡ç®—å‡ºæ¥çš„K/Våé¢è¦ç»™åˆ°åé¢Expertç”¨ä½œcrossçš„K/Vã€‚</p>
<p>ä¸Šé¢å‰ç¼€è‡ªæ³¨æ„åŠ›åªæœ‰åªæœ‰è®­ç»ƒçš„æ¨¡å‹çš„æ—¶å€™è¿›å…¥äº¤å‰æ³¨æ„åŠ›æ¯æ¬¡éƒ½ä¼šè·‘ï¼Œåœ¨æ¨ç†é˜¶æ®µæ—¶æ¯æ¬¡æ¨ç†åªä¼šè·‘ä¸€æ¬¡ã€‚</p>
<p><strong>ï¼ˆ2ï¼‰K/V cacheç¼“å­˜å¤„ç†</strong></p>
<div class="codehilite"><pre><span></span><code><span class="k">if</span> <span class="n">use_cache</span> <span class="ow">and</span> <span class="n">past_key_values</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">past_key_values</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">if</span> <span class="n">use_cache</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">fill_kv_cache</span><span class="p">:</span>
        <span class="n">past_key_values</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"key_states"</span><span class="p">:</span> <span class="n">key_states</span><span class="p">,</span> <span class="s2">"value_states"</span><span class="p">:</span> <span class="n">value_states</span><span class="p">}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">key_states</span>   <span class="o">=</span> <span class="n">past_key_values</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">][</span><span class="s2">"key_states"</span><span class="p">]</span>
        <span class="n">value_states</span> <span class="o">=</span> <span class="n">past_key_values</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">][</span><span class="s2">"value_states"</span><span class="p">]</span>
</code></pre></div>
<p>æ¨ç†çš„æ—¶å€™ä¼šç”¨åˆ°ç¼“å­˜ï¼Œåœ¨æ¨ç†æ—¶ä¼šè°ƒç”¨ä¸¤æ¬¡forwardã€‚</p>
<ul>
<li>å»ºç¼“å­˜é˜¶æ®µï¼ˆprefix-onlyï¼‰ï¼šå¤–å±‚ä¼šå…ˆå•ç‹¬è·‘ä¸€éï¼Œåªç»™ inputs_embeds=[prefix_embs, None]ï¼Œfill_kv_cache=Trueï¼ŒæŠŠ VLM prefix çš„ K/V å­˜åˆ° past_key_values[layer_idx]ã€‚</li>
<li>åç¼€é˜¶æ®µï¼ˆçœŸæ­£ crossï¼‰ï¼šç”¨ inputs_embeds=[prefix_embs, suffix_embs] æˆ–è€…åªç»™ suffixï¼Œfill_kv_cache=Falseï¼Œæ­¤æ—¶ç›´æ¥å¤ç”¨ç¼“å­˜é‡Œçš„ prefix K/Vï¼Œä¸ç”¨å†ç®—ã€‚</li>
</ul>
<p><strong>ï¼ˆ3ï¼‰Expertçš„äº¤å‰æ³¨æ„åŠ›</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">expert_layer</span> <span class="o">=</span> <span class="n">model_layers</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">layer_idx</span><span class="p">]</span>   <span class="c1"># å– Expert çš„ç¬¬ layer_idx å±‚ï¼ˆå¯èƒ½æ˜¯ Noneï¼‰</span>
<span class="k">if</span> <span class="n">expert_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">expert_hidden_states</span> <span class="o">=</span> <span class="n">expert_layer</span><span class="o">.</span><span class="n">input_layernorm</span><span class="p">(</span><span class="n">inputs_embeds</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</code></pre></div>
<p>expert_layer is None çš„å‡ºç°æ˜¯ç”± get_model_layers å¯¹é½è§„åˆ™å†³å®šçš„ï¼Œmultiple_of = num_vlm_layers // num_expert_layersã€‚Expertè¦èƒ½å¤Ÿè®¡ç®—äº¤å‰æ³¨æ„åŠ›ä¹Ÿè¦æ»¡è¶³å½“å‰å±‚æ˜¯å¦æœ‰Expertå±‚ã€‚å› ä¸ºVLMå’ŒExpertæ˜¯å¯¹é½çš„ï¼Œä¸ä¸€å®šæ¯ä¸€å±‚éƒ½æœ‰Expertï¼Œè€Œå½“self_attn_every_n_layersè®¾ç½®ä¸º2æ—¶ï¼Œç›¸å½“äºæ˜¯å¥‡æ•°å±‚æ‰ä¼šè‡ªæ³¨æ„åŠ›ï¼Œè€Œå½“VLMä¸º16ï¼ŒExpertä¸º8,é‚£ä¹ˆæ­£å¥½Expertéƒ½åœ¨å¶æ•°å±‚åŸºæ•°å±‚æ²¡æœ‰ï¼Œæ‰€ä»¥æ•´ä¸ªæ¨¡å‹éƒ½æ²¡æœ‰æ³¨æ„åŠ›æœºåˆ¶è®¡ç®—ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="n">expert_query_state</span> <span class="o">=</span> <span class="n">expert_layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">q_proj</span><span class="p">(</span><span class="n">expert_hidden_states</span><span class="p">)</span> \
                         <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">Ls</span><span class="p">,</span> <span class="n">He</span><span class="p">,</span> <span class="n">Dhe</span><span class="p">)</span>
<span class="c1"># å…ˆæŠŠ VLM çš„ K/V åˆå¹¶ head ç»´ï¼Œå˜ä¸º [B, Lp, H*Dh]</span>
<span class="n">_key_states</span>   <span class="o">=</span> <span class="n">key_states</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">expert_layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">k_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">key_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">_value_states</span> <span class="o">=</span> <span class="n">value_states</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">expert_layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">v_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">value_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># å†å–‚ç»™ Expert è‡ªå·±çš„ k_proj/v_projï¼ŒæŠŠç»´åº¦æ˜ å°„åˆ° Expert çš„å¤´æ•°ä¸ head_dim</span>
<span class="n">expert_key_states</span>   <span class="o">=</span> <span class="n">expert_layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">k_proj</span><span class="p">(</span><span class="n">_key_states</span><span class="p">)</span> \
                         <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">_key_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>   <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">expert_layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>   <span class="c1"># [B, Lp, He, Dhe]</span>
<span class="n">expert_value_states</span> <span class="o">=</span> <span class="n">expert_layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">v_proj</span><span class="p">(</span><span class="n">_value_states</span><span class="p">)</span> \
                         <span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">_value_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">expert_layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">head_dim</span><span class="p">)</span>
</code></pre></div>
<p>Expertçš„expert_query_stateæ¥è‡ªè‡ªå·±çš„è¾“å…¥ï¼Œè€Œexpert_key_statesã€expert_value_statesæ¥ä¹‹ä¸key_statesã€value_stateså³ä¸ºVLMè®¡ç®—è¿‡æ¥çš„ç¼“å­˜K/Vã€‚ä¹Ÿå°±æ˜¯Expertè®¡ç®—æ³¨æ„åŠ›æ˜¯Qä½¿ç”¨è‡ªå·±çš„ï¼Œè€ŒK/Vä½¿ç”¨çš„æ˜¯VLMçš„ã€‚ä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯å¯èƒ½ä¸¤è¾¹çš„æ¨¡å‹VLMå’ŒExpertçš„hiddenå®½åº¦ã€KVå¤´æ•°/ç»´åº¦ä¸ä¸€æ ·ï¼Œå…ˆæŠŠ VLM K/V çš„å¤šå¤´ç»´åˆå¹¶ï¼ˆview(*, H*Dh)ï¼‰ï¼Œå†ç”¨ Expert è‡ªå·±çš„ k_proj/v_proj åšä¸€æ¬¡çº¿æ€§å˜æ¢ï¼Œæ˜ å°„åˆ° Expert çš„å¤šå¤´ç»´åº¦ã€‚è¿™å°±æ˜¯ä»£ç é‡Œ â€œcross K/V é€‚é…å±‚â€ çš„ä½œç”¨ï¼›å¯¹åº”åˆ° <strong>init</strong>ï¼Œå½“ attention_mode åŒ…å« "cross" æ—¶ï¼Œä¼šæŠŠ Expert çš„ k_proj/v_proj é‡å®šä¹‰æˆè¾“å…¥ç»´=VLM çš„ kv_heads x head_dimï¼Œè¾“å‡ºç»´=Expert çš„ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># è®© Expert çš„ token ä½ç½®ä» 0 å¼€å§‹ï¼ˆRoPE éœ€è¦ç›¸å¯¹ä½ç½®ï¼‰</span>
<span class="n">expert_position_id</span> <span class="o">=</span> <span class="n">expert_position_id</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">expert_position_id</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># è¡Œé€‰æ‹© Expert çš„ queriesï¼ˆåç¼€é‚£æ®µï¼‰ï¼Œåˆ—åªåˆ° prefix çš„ K/V é•¿åº¦ï¼ˆä¸¥æ ¼ crossï¼Œä¸çœ‹è‡ªå·±ï¼‰</span>
<span class="n">expert_attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="o">-</span><span class="n">inputs_embeds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:,</span> <span class="p">:</span> <span class="n">expert_key_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="p">]</span>

<span class="c1"># å¯¹ Expert çš„ Query æ–½åŠ  RoPE</span>
<span class="n">expert_query_states</span> <span class="o">=</span> <span class="n">apply_rope</span><span class="p">(</span><span class="n">expert_query_state</span><span class="p">,</span> <span class="n">expert_position_id</span><span class="p">)</span>

<span class="n">att_output</span> <span class="o">=</span> <span class="n">attention_interface</span><span class="p">(</span><span class="n">expert_attention_mask</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">,</span>
                                 <span class="n">expert_query_states</span><span class="p">,</span> <span class="n">expert_key_states</span><span class="p">,</span> <span class="n">expert_value_states</span><span class="p">)</span>
<span class="n">att_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">att_output</span><span class="p">)</span>
</code></pre></div>
<p>æ¥ä¸‹æ¥å°±æ˜¯è®¡ç®—maskï¼Œç¡®ä¿Expertè®¡ç®—crossæ—¶åªçœ‹åˆ°å‰ç¼€ï¼ˆçº¯cross-attnï¼‰ï¼Œä¸èƒ½è‡ªå›çœ‹ï¼ˆä¸çœ‹åç¼€è‡ªèº«ï¼‰ã€‚å†è®¡ç®—RoPEçš„ä½ç½®ç¼–ç ï¼Œæœ€åè°ƒç”¨attention_interfaceè®¡ç®—äº¤å‰æ³¨æ„åŠ›å¾—åˆ°ç»“æœè¾“å‡ºã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">return</span> <span class="n">att_outputs</span><span class="p">,</span> <span class="n">past_key_values</span>
</code></pre></div>
<p>æœ€ç»ˆè¿”å›çš„æ˜¯ä¸¤ä¸ªæµå¯¹åº”çš„è‡ªæ³¨æ„åŠ›è¾“å‡ºï¼Œatt_outputs çš„ é•¿åº¦ä¸ inputs_embeds å¯¹é½ï¼Œç´¢å¼•0ä»£è¡¨VLM æµçš„è¾“å‡ºï¼ˆå‰é¢ prefix è‡ªæ³¨æ„åŠ›çš„ç»“æœï¼‰ï¼›ç´¢å¼• 1 ä»£è¡¨Expert æµçš„è¾“å‡ºï¼ˆæœ¬å±‚ cross çš„ç»“æœï¼›æ²¡æœ‰ Expert å°±æ˜¯ Noneï¼‰ã€‚å¤–å±‚ä¸»å¾ªç¯ä¼šæ®æ­¤å¯¹ä¸¤ä¸ªæµåˆ†åˆ«è¿‡ o_proj + æ®‹å·® + MLP ç­‰ï¼Œç»§ç»­ä¸‹ä¸€å±‚ã€‚</p>
<p><a href="https://www.laumy.tech/wp-content/uploads/2025/08/wp_editor_md_eaba9df551b693207c8543974bc2de9c_1756287909.png"><img alt="" src="assets/doc/04-ai/lerobot/lerobot-smolvlaç­–ç•¥/images/wp_editor_md_eaba9df551b693207c8543974bc2de9c_1756287909.png"/></a></p>
<p>æ€»ç»“ä¸€ä¸‹ï¼šcross-attn åˆ†æ”¯â€œä¸æ‹¼æ¥ Expert çš„ K/Vâ€ï¼šExpert çš„ Q åªå¯¹ VLM çš„ K/Vï¼ˆç»æŠ•å½±åˆ° Expert ç»´åº¦ï¼‰åšæ³¨æ„ã€‚è®­ç»ƒæ—¶VLM K/Vç°åœºç®—å‡ºå¹¶å¯é€‰æ‹©å†™å…¥ç¼“å­˜ï¼›Expert Q åªçœ‹è¿™ä»½ VLM K/Vã€‚æ¨ç†æ—¶å…ˆç”¨å‰ç¼€é˜¶æ®µå¡«å¥½ VLM KV ç¼“å­˜ï¼›å»å™ªæ—¶ Expert Q ç›´æ¥ç”¨ç¼“å­˜çš„ VLM K/Vã€‚VLM ä¸äº§ç”Ÿ Qï¼Œä¸ä¼šâ€œçœ‹â€Expertã€‚</p>
<p><strong>Expertè¦è®¡ç®—äº¤å‰æ³¨æ„åŠ›éœ€è¦æ»¡è¶³ä»€ä¹ˆæ¡ä»¶ï¼Ÿ</strong></p>
<p>ä¸»è¦çœ‹3ä¸ªå‚æ•°</p>
<ul>
<li>L = num_vlm_layersï¼šVLM æ€»å±‚æ•°</li>
<li>E = num_expert_layersï¼šExpert æ€»å±‚æ•°ï¼ˆå¿…é¡» &gt; 0 ä¸”èƒ½æ•´é™¤ Lï¼‰</li>
<li>S = self_attn_every_n_layersï¼šæ¯éš” S å±‚å¼ºåˆ¶èµ°ä¸€æ¬¡è‡ªæ³¨æ„åŠ›ï¼ˆ=è¿™å±‚ä¸åš crossï¼‰</li>
</ul>
<p><strong>æŸå±‚åš cross çš„æ¡ä»¶ : i % M 0 ä¸”ï¼ˆS = 0 æˆ– i % S != 0ï¼‰</strong></p>
<p>ä¸¾ä¾‹1ï¼šL=16, E=8ï¼›æœ‰Expertçš„å±‚æ˜¯{0,2,4,6,8,10,12,14}ï¼Œè‹¥S=2è¿™äº›å±‚å…¨æ˜¯Sçš„å€æ•°ï¼Œé‚£ä¹ˆæ²¡æœ‰ä¸€å±‚åšcrossã€‚è‹¥S=3ï¼Œåšcrossçš„ä¸º{2,4,8,10,14}ã€‚</p>
<p>æ€»ç»“ä¸€ä¸‹å°±æ˜¯èƒ½åšcrossçš„ï¼Œå…ˆçœ‹æ¯éš”å‡ å±‚åšcrossï¼ˆé—´æ¥æœ‰self_attn_every_n_layerså†³å®šï¼‰åŒæ—¶è¦æ»¡è¶³èƒ½åšcrossçš„è¿™å‡ å±‚æœ‰æ²¡æœ‰Expertã€‚ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå½“VLMå’ŒExpertå…·æœ‰ç›¸åŒå±‚æ•°æ˜¯ï¼Œå¥‡æ•°å±‚åšCrossï¼Œå¦‚æœExpertä¸ºVLMçš„ä¸€åŠæ˜¯éœ€è¦è®¾ç½®self_attn_every_n_layersè®¾ç½®å¤§äº2ä»¥ä¸Šçš„å¥‡æ•°æ‰èƒ½åšcrossã€‚</p>
<table>
<thead>
<tr>
<th>å±‚ç±»å‹</th>
<th>è®­ç»ƒæ—¶</th>
<th>æ¨ç†æ—¶</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Self-Attn</strong></td>
<td>VLM &amp; Expert å„è‡ªç®— QKV â†’ æ‹¼æ¥ â†’ åŒå‘æ³¨æ„ â†’ åˆ‡åˆ†ç»“æœ</td>
<td>åŒè®­ç»ƒï¼Œä½† prefix KV åœ¨é¦–è½®ç¼“å­˜ï¼Œåç»­å¤ç”¨ï¼›åŒå‘ä¾æ—§å­˜åœ¨ï¼Œä½† VLM å†»ç»“</td>
</tr>
<tr>
<td><strong>Cross-Attn</strong></td>
<td>VLM è‡ªæ³¨æ„æ›´æ–°è‡ªèº« KVï¼›Expert åªç®— Qï¼Œä» VLM KVï¼ˆçº¿æ€§æŠ•å½±åï¼‰è¯»æ¡ä»¶</td>
<td>prefix KV å·²ç¼“å­˜ï¼›Expert åªç®— Qï¼Œç›´æ¥è¯»ç¼“å­˜çš„ VLM KVï¼›æ— éœ€é‡å¤è®¡ç®—</td>
</tr>
</tbody>
</table>
<h2 id="_13">æ¨¡å‹é…ç½®</h2>
<h3 id="smolvlaconfig">SmolVLAConfig</h3>
<p>æ¨¡å‹é…ç½®ä¸»è¦æ˜¯SmolVLAConfigç±»ï¼Œå…¶å†³å®šäº†è®­ç»ƒ/æ¨ç†æ˜¯æ¨¡å‹ç»“æ„ã€é¢„å¤„ç†ã€ä¼˜åŒ–å™¨/è°ƒåº¦å™¨ã€ä»¥åŠVLMéª¨å¹²é€‰æ‹©ä¸å†»ç»“ç­–ç•¥ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">SmolVLAConfig</span><span class="p">(</span><span class="n">PreTrainedConfig</span><span class="p">):</span>
    <span class="c1"># Input / output structure.</span>
    <span class="n">n_obs_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">chunk_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">n_action_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span>

    <span class="n">normalization_mapping</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">NormalizationMode</span><span class="p">]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="k">lambda</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">"VISUAL"</span><span class="p">:</span> <span class="n">NormalizationMode</span><span class="o">.</span><span class="n">IDENTITY</span><span class="p">,</span>
            <span class="s2">"STATE"</span><span class="p">:</span> <span class="n">NormalizationMode</span><span class="o">.</span><span class="n">MEAN_STD</span><span class="p">,</span>
            <span class="s2">"ACTION"</span><span class="p">:</span> <span class="n">NormalizationMode</span><span class="o">.</span><span class="n">MEAN_STD</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Shorter state and action vectors will be padded</span>
    <span class="n">max_state_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>
    <span class="n">max_action_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span>

    <span class="c1"># Image preprocessing</span>
    <span class="n">resize_imgs_with_padding</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

    <span class="c1"># Add empty images. Used by smolvla_aloha_sim which adds the empty</span>
    <span class="c1"># left and right wrist cameras in addition to the top camera.</span>
    <span class="n">empty_cameras</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Converts the joint and gripper values from the standard Aloha space to</span>
    <span class="c1"># the space used by the pi internal runtime which was used to train the base model.</span>
    <span class="n">adapt_to_pi_aloha</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Converts joint dimensions to deltas with respect to the current state before passing to the model.</span>
    <span class="c1"># Gripper dimensions will remain in absolute values.</span>
    <span class="n">use_delta_joint_actions_aloha</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Tokenizer</span>
    <span class="n">tokenizer_max_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">48</span>

    <span class="c1"># Decoding</span>
    <span class="n">num_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="c1"># Attention utils</span>
    <span class="n">use_cache</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Finetuning settings</span>
    <span class="n">freeze_vision_encoder</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">train_expert_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">train_state_proj</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Training presets</span>
    <span class="n">optimizer_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">optimizer_betas</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">)</span>
    <span class="n">optimizer_eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
    <span class="n">optimizer_weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-10</span>
    <span class="n">optimizer_grad_clip_norm</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">10</span>

    <span class="n">scheduler_warmup_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1_000</span>
    <span class="n">scheduler_decay_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">30_000</span>
    <span class="n">scheduler_decay_lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.5e-6</span>

    <span class="n">vlm_model_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"HuggingFaceTB/SmolVLM2-500M-Video-Instruct"</span>  <span class="c1"># Select the VLM backbone.</span>
    <span class="n">load_vlm_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Set to True in case of training the expert from scratch. True when init from pretrained SmolVLA weights</span>

    <span class="n">add_image_special_tokens</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Whether to use special image tokens around image features.</span>

    <span class="n">attention_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"cross_attn"</span>

    <span class="n">prefix_length</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="n">pad_language_to</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"longest"</span>  <span class="c1"># "max_length"</span>

    <span class="n">num_expert_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>  <span class="c1"># Less or equal to 0 is the default where the action expert has the same number of layers of VLM. Otherwise the expert have less layers.</span>
    <span class="n">num_vlm_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># Number of layers used in the VLM (first num_vlm_layers layers)</span>
    <span class="n">self_attn_every_n_layers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># Interleave SA layers each self_attn_every_n_layers</span>
    <span class="n">expert_width_multiplier</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.75</span>  <span class="c1"># The action expert hidden size (wrt to the VLM)</span>

    <span class="n">min_period</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4e-3</span>  <span class="c1"># sensitivity range for the timestep used in sine-cosine positional encoding</span>
    <span class="n">max_period</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span>
</code></pre></div>
<p>å¯ä»¥åˆ†ä¸ºå‡ ä¸ªéƒ¨åˆ†</p>
<p><strong>ï¼ˆ1ï¼‰è¾“å…¥è¾“å‡ºä¸æ—¶åº</strong></p>
<ul>
<li>n_obs_steps: è¾“å…¥è§‚æµ‹çš„å†å²æ­¥æ•°ï¼Œé»˜è®¤ä¸º1ã€‚</li>
<li>chunk_size:æ¯æ¬¡æ¨¡å‹ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—é•¿åº¦ï¼ˆåç¼€åºåˆ—é•¿åº¦ï¼‰ã€‚</li>
<li>n_action_stepsï¼šå¤–éƒ¨æ¶ˆè´¹çš„åŠ¨ä½œæ­¥æ•°ï¼Œéœ€è¦æ»¡è¶³n_action_steps &lt;= chunk_sizeï¼ˆä»£ç ä¸­å·²æ ¡éªŒï¼‰ã€‚</li>
</ul>
<p>é‡‡æ ·ä¸è®­ç»ƒçš„åç¼€é•¿åº¦åœ¨ VLAFlowMatching.sample_actions/forward ä¸­ä½¿ç”¨ï¼ŒåŠ¨ä½œé˜Ÿåˆ—åœ¨ SmolVLAPolicy ä¸­æŒ‰ n_action_steps å‡ºé˜Ÿã€‚</p>
<p><strong>ï¼ˆ2ï¼‰å½’ä¸€åŒ–ä¸ç‰¹å¾ç»´åº¦</strong></p>
<ul>
<li>normalization_mappingï¼šå„æ¨¡æ€çš„æ ‡å‡†åŒ–ç­–ç•¥ï¼Œè§†è§‰é»˜è®¤ Identityï¼ŒçŠ¶æ€ä¸åŠ¨ä½œ MeanStdã€‚</li>
<li>max_state_dim/max_action_dimï¼šçŠ¶æ€ã€åŠ¨ä½œå‘é‡çš„å›ºå®šä¸Šé™ç»´åº¦ï¼›çŸ­å‘é‡ä¼š pad åˆ°è¯¥ç»´åº¦ï¼ˆpad_vectorï¼‰ã€‚</li>
</ul>
<p>Normalize/Unnormalize ä¸ state_proj/action_ x _proj çš„æŠ•å½±ç»´åº¦ã€‚</p>
<p><strong>ï¼ˆ3ï¼‰å›¾åƒé¢„å¤„ç†ä¸ç©ºç›¸æœº</strong></p>
<ul>
<li>resize_imgs_with_padding=(512,512)ï¼šè§†è§‰è¾“å…¥ pad-resize åˆ°å›ºå®šåˆ†è¾¨ç‡ï¼Œç„¶åå†åš [-1,1] å½’ä¸€åŒ–ï¼ˆSigLIP ä¹ æƒ¯ï¼‰ã€‚</li>
<li>empty_camerasï¼šå…è®¸åœ¨ batch ç¼ºå°‘å›¾åƒæ—¶è¡¥ç©ºç›¸æœºå ä½ï¼ˆç”¨äºå¤šæ‘„åƒå¤´ä½†éƒ¨åˆ†ç¼ºå¤±çš„åœºæ™¯ï¼‰ã€‚</li>
</ul>
<p><strong>ï¼ˆ4ï¼‰Aloha ç›¸å…³å¼€å…³</strong></p>
<ul>
<li>adapt_to_pi_alohaï¼šçŠ¶æ€/åŠ¨ä½œä¸ Aloha ç©ºé—´çš„åŒå‘è½¬æ¢ï¼ˆå…³èŠ‚ç¿»è½¬ã€å¤¹çˆªè§’åº¦/çº¿æ€§ç©ºé—´äº’è½¬ï¼‰ã€‚</li>
<li>use_delta_joint_actions_alohaï¼šå°†å…³èŠ‚ç»´åº¦è½¬ä¸ºç›¸å¯¹é‡ï¼ˆç›®å‰æœªåœ¨ LeRobot ä¸­å®ç°ï¼Œç½® True ä¼šæŠ¥é”™ï¼‰ã€‚</li>
</ul>
<p><strong>ï¼ˆ5ï¼‰æ–‡æœ¬ä¸é‡‡æ ·æ­¥æ•°</strong></p>
<ul>
<li>tokenizer_max_length=48ï¼šè¯­è¨€ token æœ€å¤§é•¿åº¦ã€‚</li>
<li>num_steps=10ï¼šFlow Matching åæ¨ç†çš„ Euler æ­¥æ•°ï¼ˆè¶Šå¤§è¶Šç²¾ç»†ï¼Œè¶Šæ…¢ï¼‰ã€‚</li>
</ul>
<p>prepare_languageã€sample_actions çš„è¿­ä»£å»å™ªå¾ªç¯ã€‚</p>
<p><strong>ï¼ˆ6ï¼‰ç¼“å­˜ä¸æ³¨æ„åŠ›</strong></p>
<ul>
<li>use_cache=Trueï¼šæ˜¯å¦ä½¿ç”¨ KV-Cacheï¼ˆå‰ç¼€åªç®—ä¸€æ¬¡ï¼Œåç»­é‡å¤ç”¨ï¼‰ã€‚</li>
<li>attention_mode="cross_attn"ï¼šä¸ SmolVLMWithExpertModel çš„äº¤å‰æ³¨æ„åŠ›å¯¹é½ç­–ç•¥ã€‚</li>
<li>prefix_length=-1/pad_language_to="longest"ï¼šå‰ç¼€é•¿åº¦/è¯­è¨€ padding ç­–ç•¥ï¼›ç”¨äºæ„é€  attention_mask ä¸ position_idsã€‚</li>
</ul>
<p><strong>ï¼ˆ7ï¼‰å¾®è°ƒçš„ç­–ç•¥</strong></p>
<ul>
<li>freeze_vision_encoder=Trueï¼šå†»ç»“ VLM è§†è§‰ç¼–ç å™¨ã€‚</li>
<li>train_expert_only=Trueï¼šåªè®­ç»ƒåŠ¨ä½œ expertï¼ˆVLM å…¶å®ƒéƒ¨åˆ†å†»ç»“ï¼‰ã€‚</li>
<li>train_state_proj=Trueï¼šæ˜¯å¦è®­ç»ƒçŠ¶æ€æŠ•å½±å±‚ã€‚</li>
</ul>
<p>å½±å“SmolVLMWithExpertModel.set_requires_grad ä»¥åŠ VLM å‚æ•°çš„ requires_grad è®¾ç½®ã€‚</p>
<p><strong>ï¼ˆ8ï¼‰ä¼˜åŒ–å™¨ä¸è°ƒåº¦å™¨</strong></p>
<ul>
<li>optimizer_* ä¸ scheduler_*ï¼šåœ¨è®­ç»ƒå…¥å£ TrainPipelineConfig.validate() ä½¿ç”¨ï¼Œç”Ÿæˆé»˜è®¤çš„ AdamW + ä½™å¼¦é€€ç«å¸¦é¢„çƒ­è°ƒåº¦ã€‚</li>
</ul>
<p>å¯è¢« CLI è¦†å†™ï¼ˆå¦‚ --optimizer.lr ç­‰ï¼‰ã€‚</p>
<p><strong>ï¼ˆ9ï¼‰VLMéª¨å¹²ä¸æƒé‡åŠ è½½</strong></p>
<ul>
<li>vlm_model_name="HuggingFaceTB/SmolVLM2-500M-Video-Instruct"ï¼šæŒ‡å®šç”¨å“ªä¸ª VLM ä»“åº“ï¼ˆç”¨äºå– tokenizer/processorï¼Œå’Œæ„å»ºéª¨å¹²ç»“æ„ï¼‰ã€‚</li>
<li>load_vlm_weights=Falseï¼šæ˜¯å¦ç›´æ¥ä»è¯¥ VLM ä»“åº“ä¸‹è½½éª¨å¹²æƒé‡ã€‚ä¸º Falseæ—¶åªæ‹¿ AutoConfig æ„ç»“æ„ï¼Œæƒé‡éšæœºåˆå§‹åŒ–ï¼Œéšåé€šå¸¸è¢«ç­–ç•¥æ£€æŸ¥ç‚¹è¦†ç›–ã€‚ä¸º Trueæ—¶ç”¨ AutoModelForImageTextToText.from_pretrained åŠ è½½éª¨å¹²æƒé‡ï¼ˆä»…åœ¨ --policy.type=smolvla è·¯çº¿ä¸‹å¸¸ç”¨ï¼‰ã€‚</li>
</ul>
<p>ä¸ --policy.path çš„å…³ç³»ä¸ºç”¨ --policy.path=lerobot/smolvla_base æ—¶ï¼Œå®é™…æƒé‡æ¥è‡ªæœ¬åœ°/Hub çš„ç­–ç•¥æ£€æŸ¥ç‚¹ï¼ˆåŒ…å« VLM+expertï¼‰ï¼Œä¸ä¼šä½¿ç”¨éª¨å¹²æƒé‡ï¼Œä½†ä»ä¼šç”¨ vlm_model_name ä¸»è¦æ˜¯åŠ è½½ tokenizer/processorã€‚ç”¨ --policy.type=smolvla æ—¶ï¼Œvlm_model_name å†³å®šéª¨å¹²ç»“æ„ï¼Œload_vlm_weights å†³å®šæ˜¯å¦æ‹‰éª¨å¹²æƒé‡ï¼Œexpert æŒ‰æœ¬åœ°é…ç½®æ–°å»ºè®­ç»ƒã€‚</p>
<p><strong>ï¼ˆ10ï¼‰å±‚æ•°ä¸å®½åº¦å¯¹é½</strong></p>
<ul>
<li>num_vlm_layersï¼šæŠŠ VLM çš„æ–‡æœ¬å±‚è£å‰ªä¸ºå‰ N å±‚å†ç”¨ã€‚è£å‰ªå±‚æ•°åè®¾ä¸º self.num_vlm_layersã€‚</li>
<li>num_expert_layersï¼šä¸“å®¶ expert æ¨¡å‹çš„å±‚æ•°ï¼›è‹¥ â‰¤0 åˆ™é»˜è®¤ä¸ VLM å±‚æ•°ç›¸åŒã€‚å†³å®š expert ä¸ VLM çš„å±‚å¯¹é½æ­¥é•¿ multiple_of = num_vlm_layers // num_expert_layersã€‚åªæœ‰åœ¨ i % multiple_of = 0 çš„ VLM å±‚ä½ç‚¹æ‰æ˜ å°„åˆ°ä¸€ä¸ª expert å±‚ç”¨äºäº¤å‰æ³¨æ„åŠ›ï¼›å…¶ä»–å±‚çš„ expert_layer ä¸ºç©ºã€‚</li>
<li>self_attn_every_n_layersï¼šæ¯éš” n å±‚å¼ºåˆ¶èµ°â€œä»…è‡ªæ³¨æ„åŠ›â€è€Œä¸æ˜¯äº¤å‰æ³¨æ„åŠ›ã€‚å½“ attention_mode å« â€œcrossâ€ ä¸” fill_kv_cache=False æ—¶ï¼Œå¦‚æœ layer_idx % n = 0 åˆ™èµ° self-attn åˆ†æ”¯ï¼Œå¦åˆ™èµ° cross-attn åˆ†æ”¯ã€‚ä¾‹å¦‚n=2 â†’ å¶æ•°å±‚è‡ªæ³¨æ„ã€å¥‡æ•°å±‚å°è¯•äº¤å‰æ³¨æ„ï¼Œä½†è¿˜éœ€è¯¥å±‚â€œæœ‰æ˜ å°„åˆ°çš„ expert å±‚â€ï¼ˆè§ multiple_ofï¼‰æ‰çœŸæ­£æ‰§è¡Œ cross-attnã€‚</li>
<li>expert_width_multiplierï¼šexpert çš„éšè—ç»´åº¦ = VLM éšè—ç»´åº¦ Ã— multiplierï¼ˆåŒæ—¶é‡è®¾ FFN çš„ intermediate_sizeï¼‰ã€‚expert æ›´çª„ä»¥é™ç®—åŠ›ï¼›ä½†ä¼šæ”¹åŠ¨çº¿æ€§å±‚å½¢çŠ¶ï¼Œéœ€ä¸åŠ è½½çš„æ£€æŸ¥ç‚¹ä¸€è‡´ï¼Œå¦åˆ™ä¼šç»´åº¦ä¸åŒ¹é…ã€‚ä¸ºå®ç° cross-attnï¼Œä»£ç ä¼šæŒ‰ VLM hidden å°ºå¯¸é‡å»ºéƒ¨åˆ† q/k/v æŠ•å½±ï¼Œä½¿å…¶èƒ½æ¥æ”¶æ¥è‡ª VLM çš„è¾“å…¥ï¼ˆè·³è¿‡â€œåªè‡ªæ³¨æ„â€å±‚ï¼‰ã€‚</li>
</ul>
<p>åœ¨SmolVLAConfigé…ç½®é›†ä¸­å®šä¹‰äº† SmolVLA çš„â€œç»“æ„ä¸è®­ç»ƒ/æ¨ç†å¼€å…³â€ã€‚è®­ç»ƒå¾®è°ƒå¸¸ç”¨ --policy.path=lerobot/smolvla_baseï¼Œæ­¤æ—¶å¤šæ•°ç»“æ„å‚æ•°ä¸å®œä¿®æ”¹ï¼Œå¾®è°ƒæ—¶ä»smolvla_baseä¸­åŠ è½½config.jsoné…ç½®ï¼›è€Œä»éª¨å¹²è‡ªå»ºè®­ç»ƒæ—¶æ‰éœ€è¦ç²¾ç»†è°ƒ num_expert_layers/num_vlm_layers/expert_width_multiplier/load_vlm_weights ç­‰ï¼Œå¹¶ç¡®ä¿ä¸éª¨å¹² hidden_size/å±‚æ•°ä¸€è‡´ã€‚</p>
<h3 id="_14">åŠ è½½æµç¨‹</h3>
<p>ç­–ç•¥çš„åŠ è½½ä¸»è¦åˆ†ä¸ºä¸¤æ¡å…¥å£è·¯å¾„ï¼Œä¸¤è€…äº’æ–¥ï¼Œé€šè¿‡å¯åŠ¨æ—¶å‚æ•°æŒ‡å®šã€‚</p>
<p><strong>ï¼ˆ1ï¼‰--policy.path=....æ–¹å¼</strong></p>
<p>ç”¨ --policy.path=.....:æŒ‡å®šä¸€ä¸ªå·²å­˜åœ¨çš„ç­–ç•¥checkpointï¼ˆHub ä¸Šæˆ–æœ¬åœ°ç›®å½•ï¼‰ã€‚å¦‚è®­ç»ƒæ—¶å¾®è°ƒå¯ä»¥æŒ‡å®šlerobot/smolvla_baseï¼Œæ¨ç†æ—¶æŒ‡å®šoutput/train/pretrained_modelã€‚ä¼šä» path/config.json é‡Œååºåˆ—åŒ–æˆ SmolVLAConfigï¼›ä¼šåŠ è½½åŒç›®å½•ä¸‹çš„ model.safetensorsï¼ˆæ•´ä¸ªç­–ç•¥æƒé‡ï¼šVLMéª¨å¹² + åŠ¨ä½œä¸“å®¶ + æŠ•å½±å±‚ç­‰ï¼‰ï¼›è®­ç»ƒå¼€å§‹æ—¶ï¼Œæ¨¡å‹å·²ç»æœ‰äº†ä¸€å¥—å®Œæ•´çš„åˆå§‹åŒ–å‚æ•°ï¼ˆé€šå¸¸æ˜¯é¢„è®­ç»ƒå¥½çš„ï¼‰ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">lerobot</span><span class="o">.</span><span class="n">scripts</span><span class="o">.</span><span class="n">train</span> \
  <span class="o">--</span><span class="n">policy</span><span class="o">.</span><span class="n">path</span><span class="o">=</span><span class="n">lerobot</span><span class="o">/</span><span class="n">smolvla_base</span> \
  <span class="o">--</span><span class="n">dataset</span><span class="o">.</span><span class="n">repo_id</span><span class="o">=</span><span class="n">xxx</span> \
  <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span> <span class="o">--</span><span class="n">steps</span><span class="o">=</span><span class="mi">200000</span>
</code></pre></div>
<p>è¿™é‡Œä¼šæ‹¿ Hugging Face Hub ä¸Šçš„ lerobot/smolvla_baseï¼ˆå« config.json + model.safetensorsï¼Œæ•´ä¸ªç­–ç•¥æƒé‡ï¼šVLMéª¨å¹² + åŠ¨ä½œä¸“å®¶ + æŠ•å½±å±‚ç­‰ï¼‰æ¥åˆå§‹åŒ–ã€‚</p>
<p><strong>ï¼ˆ2ï¼‰--policy.type=smolvlaæ–¹å¼</strong> æŒ‡å®šä¸€ä¸ª ç­–ç•¥ç±»åˆ«ï¼ˆç”± @PreTrainedConfig.register_subclass("smolvla") æ³¨å†Œï¼‰ã€‚ä¼šåˆ›å»ºä¸€ä¸ªå…¨æ–°çš„ SmolVLAConfig å¯¹è±¡ï¼ˆå¸¦é»˜è®¤è¶…å‚ï¼‰ï¼Œè€Œä¸æ˜¯åŠ è½½ checkpointã€‚æ²¡æœ‰é¢„è®­ç»ƒæƒé‡ï¼Œé™¤éé…åˆ load_vlm_weights=Trueï¼Œè¿™æ—¶åªä¼šæ‹‰å–çº¯VLMèƒŒéª¨çš„é¢„è®­ç»ƒæƒé‡ï¼ˆè€ŒåŠ¨ä½œä¸“å®¶å±‚ä»ç„¶æ˜¯éšæœºåˆå§‹åŒ–ï¼‰ã€‚å¯ä»¥ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–ä»»æ„è¶…å‚ï¼ˆæ¯”å¦‚ --policy.num_expert_layers=4ï¼‰ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">lerobot</span><span class="o">.</span><span class="n">scripts</span><span class="o">.</span><span class="n">train</span> \
  <span class="o">--</span><span class="n">policy</span><span class="o">.</span><span class="n">type</span><span class="o">=</span><span class="n">smolvla</span> \
  <span class="o">--</span><span class="n">dataset</span><span class="o">.</span><span class="n">repo_id</span><span class="o">=</span><span class="n">xxx</span> \
  <span class="o">--</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span> <span class="o">--</span><span class="n">steps</span><span class="o">=</span><span class="mi">200000</span> \
  <span class="o">--</span><span class="n">policy</span><span class="o">.</span><span class="n">load_vlm_weights</span><span class="o">=</span><span class="kc">True</span>
</code></pre></div>
<p>ä»é›¶ï¼ˆæˆ–ä»…ç”¨ VLM é¢„è®­ç»ƒéª¨å¹²ï¼‰å¼€å§‹è®­ç»ƒä¸€ä¸ªæ–°ç­–ç•¥ã€‚</p>
<p>ä¸‹é¢ä»¥æ¨ç†å’Œè®­ç»ƒä¸¾ä¾‹è¯´æ˜å…¶è°ƒç”¨æµç¨‹ã€‚</p>
<p><strong>ï¼ˆ1ï¼‰è®­ç»ƒä½¿ç”¨policy.pathæ–¹å¼</strong></p>
<p>åœ¨ validate() ä¸­è¯»å– pathï¼Œå¹¶æŠŠæ‰€æœ‰ --policy.xxx ä½œä¸ºâ€œåŒå±‚è¦†å†™â€ä¼ å…¥é…ç½®åŠ è½½ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="n">policy_path</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">get_path_arg</span><span class="p">(</span><span class="s2">"policy"</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">PreTrainedConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">policy_path</span><span class="p">,</span> <span class="n">cli_overrides</span><span class="o">=</span><span class="n">cli_overrides</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">pretrained_path</span> <span class="o">=</span> <span class="n">policy_path</span>
</code></pre></div>
<p>åˆ¤æ–­æ˜¯ä»æœ¬åœ°ç›®å½•è¿˜æ˜¯Hubä¸‹è½½è·å–é…ç½®æ–‡ä»¶ï¼Œç„¶ååº”ç”¨å¾—åˆ° SmolVLAConfigã€‚åªåŠ è½½â€œé…ç½®â€ï¼ˆconfig.jsonï¼‰ï¼Œä¸åŠ è½½æ¨¡å‹æƒé‡ã€‚æƒé‡åŠ è½½å‘ç”Ÿåœ¨åç»­ policy_cls.from_pretrained(...)ï¼ˆå¦ä¸€ä¸ªç±»ï¼Œè§ policies/pretrained.pyï¼‰ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">pretrained_name_or_path</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="o">...</span><span class="p">,</span> <span class="o">**</span><span class="n">policy_kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
    <span class="n">model_id</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">pretrained_name_or_path</span><span class="p">)</span>
    <span class="c1"># 1) å†³å®šä»æœ¬åœ°ç›®å½•è¿˜æ˜¯Hubå–é…ç½®æ–‡ä»¶ï¼ˆåªå–configï¼Œä¸å–æƒé‡ï¼‰</span>
    <span class="k">if</span> <span class="n">Path</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">CONFIG_NAME</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">model_id</span><span class="p">):</span>
            <span class="n">config_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">CONFIG_NAME</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">CONFIG_NAME</span><span class="si">}</span><span class="s2"> not found in </span><span class="si">{</span><span class="n">Path</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span><span class="o">.</span><span class="n">resolve</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">config_file</span> <span class="o">=</span> <span class="n">hf_hub_download</span><span class="p">(</span><span class="n">repo_id</span><span class="o">=</span><span class="n">model_id</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">CONFIG_NAME</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">HfHubHTTPError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">FileNotFoundError</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="kn">from</span> <span class="nn">e</span>

    <span class="c1"># 2) åº”ç”¨CLIè¦†å†™ï¼ˆå¦‚ --policy.xxx=...ï¼‰</span>
    <span class="n">cli_overrides</span> <span class="o">=</span> <span class="n">policy_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"cli_overrides"</span><span class="p">,</span> <span class="p">[])</span>
    <span class="k">with</span> <span class="n">draccus</span><span class="o">.</span><span class="n">config_type</span><span class="p">(</span><span class="s2">"json"</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">draccus</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config_file</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="n">cli_overrides</span><span class="p">)</span>
</code></pre></div>
<p>æ„å»ºç­–ç•¥ï¼Œæ³¨å…¥æ•°æ®é›†ç‰¹å¾ä¸ç»Ÿè®¡ï¼Œè‹¥å­˜åœ¨ pretrained_path åˆ™è¿åŒæƒé‡åŠ è½½ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="n">cfg</span><span class="o">.</span><span class="n">input_features</span><span class="o">/</span><span class="n">output_features</span> <span class="o">=</span> <span class="o">...</span>
<span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">pretrained_path</span><span class="p">:</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="n">policy_cls</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="n">policy_cls</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<p>åŠ è½½æƒé‡ï¼ˆç›®å½•æˆ– Hub çš„ model.safetensorsï¼‰ï¼Œéšåè¿ç§»åˆ° deviceã€è®¾ eval()ï¼ˆè®­ç»ƒå¾ªç¯é‡Œä¼šå†åˆ‡å› train()ï¼‰ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">model_id</span><span class="p">):</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="bp">cls</span><span class="o">.</span><span class="n">_load_as_safetensor</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">policy</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">device</span><span class="p">);</span> <span class="n">policy</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</code></pre></div>
<p>SmolVLA ç‰¹å®šåˆå§‹åŒ–ï¼Œå³ä½¿èµ° pathï¼Œä»æŒ‰ vlm_model_name åŠ è½½ tokenizer/processorï¼ˆéæƒé‡ï¼‰ï¼Œå¹¶å®ä¾‹åŒ–éª¨å¹²+expertã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="bp">self</span><span class="o">.</span><span class="n">language_tokenizer</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vlm_model_name</span><span class="p">)</span><span class="o">.</span><span class="n">tokenizer</span>
<span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">VLAFlowMatching</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
</code></pre></div>
<p><strong>ï¼ˆ2ï¼‰è®­ç»ƒä½¿ç”¨policy.typeæ–¹å¼</strong></p>
<p>draccus æŒ‰ç±»å‹ç›´æ¥å®ä¾‹åŒ– SmolVLAConfigï¼ˆè¯¥ç±»å·²æ³¨å†Œï¼‰å¹¶è§£æ --policy.xxxã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@PreTrainedConfig</span><span class="o">.</span><span class="n">register_subclass</span><span class="p">(</span><span class="s2">"smolvla"</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">SmolVLAConfig</span><span class="p">(</span><span class="n">PreTrainedConfig</span><span class="p">):</span>
</code></pre></div>
<p>make_policy åŒä¸Šï¼›å› æ—  pretrained_pathï¼Œé»˜è®¤ä»é›¶æ„å»ºã€‚è‹¥é…ç½® load_vlm_weights=trueï¼Œæ‰ä¼šæŠŠéª¨å¹²æƒé‡ä» vlm_model_name æ‹‰ä¸‹æ¥ï¼ˆexpert ä»éœ€è®­ç»ƒï¼‰ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">if</span> <span class="n">load_vlm_weights</span><span class="p">:</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vlm</span> <span class="o">=</span> <span class="n">AutoModelForImageTextToText</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="o">...</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">vlm</span> <span class="o">=</span> <span class="n">SmolVLMForConditionalGeneration</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
</code></pre></div>
<p><strong>ï¼ˆ3ï¼‰æ¨ç†æ¨¡å¼åªèƒ½ä½¿ç”¨policy.pathæ–¹å¼</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">policy_path</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">get_path_arg</span><span class="p">(</span><span class="s2">"policy"</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">policy</span> <span class="o">=</span> <span class="n">PreTrainedConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">policy_path</span><span class="p">,</span> <span class="n">cli_overrides</span><span class="o">=</span><span class="n">cli_overrides</span><span class="p">)</span>
<span class="bp">self</span><span class="o">.</span><span class="n">policy</span><span class="o">.</span><span class="n">pretrained_path</span> <span class="o">=</span> <span class="n">policy_path</span>
</code></pre></div>
<p>record çš„é…ç½®æŒ‰policy.pathåŠ è½½è®­ç»ƒçš„æ¨¡å‹ï¼Œéšåé€šè¿‡ predict_action/select_action ä½¿ç”¨ç­–ç•¥è¿›è¡Œæ¨ç†ã€‚</p>
<p><strong>policy.path å¯¹æ¯” policy.type</strong></p>
<table>
<thead>
<tr>
<th>ç»´åº¦</th>
<th><strong>policy.path=...</strong></th>
<th><strong>policy.type=smolvla</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>é…ç½®æ¥æº</strong></td>
<td>ä» <strong>checkpoint ç›®å½•/Hub ä»“åº“</strong>é‡Œçš„ config.json ååºåˆ—åŒ–æˆ SmolVLAConfig</td>
<td>é€šè¿‡ @PreTrainedConfig.register_subclass("smolvla") æ–°å»ºä¸€ä¸ªé»˜è®¤ SmolVLAConfigï¼Œå‘½ä»¤è¡Œå¯è¦†å†™</td>
</tr>
<tr>
<td><strong>æƒé‡æ¥æº</strong></td>
<td>ä» <strong>checkpoint é‡Œçš„ model.safetensors</strong> åŠ è½½å®Œæ•´ç­–ç•¥æƒé‡ï¼ˆVLMéª¨å¹² + åŠ¨ä½œä¸“å®¶ + æŠ•å½±å±‚ï¼‰</td>
<td>é»˜è®¤å…¨éšæœºï¼›è‹¥ load_vlm_weights=Trueï¼Œåˆ™åªåŠ è½½ <strong>VLMéª¨å¹²</strong>æƒé‡ï¼ˆSmolVLM2ï¼‰ï¼ŒåŠ¨ä½œä¸“å®¶ä»éšæœº</td>
</tr>
<tr>
<td><strong>å½’ä¸€åŒ–ç»Ÿè®¡</strong></td>
<td><strong>ä¸ä» checkpoint æ¢å¤</strong>ï¼Œè€Œæ˜¯æ¥è‡ªæ•°æ®é›† dataset_statsï¼ˆnormalize_inputs/targetsåœ¨åŠ è½½æ—¶è¢«å¿½ç•¥ï¼‰</td>
<td>åŒå·¦</td>
</tr>
<tr>
<td><strong>Tokenizer/Processor</strong></td>
<td>ä»ç„¶ä¼šç”¨ config.vlm_model_nameï¼ˆé»˜è®¤ HuggingFaceTB/SmolVLM2ï¼‰åŠ è½½ tokenizer/processor</td>
<td>åŒå·¦</td>
</tr>
<tr>
<td><strong>å¸¸è§åœºæ™¯</strong></td>
<td>- ç›´æ¥æ¨ç†   - å¾®è°ƒå·²æœ‰ç­–ç•¥</td>
<td>- ä»é›¶å¼€å§‹è®­ç»ƒæ–°ç­–ç•¥   - æ¢ç»“æ„åšå®éªŒï¼ˆæ”¹ num_expert_layersã€expert_width_multiplierç­‰ï¼‰</td>
</tr>
<tr>
<td><strong>æ¨ç†å¯ç”¨æ€§</strong></td>
<td>ä¸€é”®å¯ç”¨ï¼ˆæƒé‡å®Œæ•´ï¼‰</td>
<td>ä¸å¯ç›´æ¥ç”¨ï¼ˆä¸“å®¶æ²¡è®­ç»ƒï¼Œè¾“å‡ºæ— æ„ä¹‰ï¼‰ï¼Œé™¤éåç»­æ‰‹åŠ¨åŠ è½½ä½ è‡ªå·±è®­ç»ƒå¥½çš„æƒé‡</td>
</tr>
<tr>
<td><strong>æ˜¯å¦éœ€è¦ HuggingFaceTB/SmolVLM2 æƒé‡</strong></td>
<td>ä¸éœ€è¦ï¼ˆåªç”¨åˆ°å®ƒçš„ processor/tokenizerï¼‰</td>
<td>å¦‚æœ load_vlm_weights=True â†’ éœ€è¦æ‹‰éª¨å¹²æƒé‡ï¼›å¦åˆ™å…¨éšæœº</td>
</tr>
</tbody>
</table></div>
  <div class="post-nav">
    <a class="prev" href="smolvla-å¼‚æ­¥æ¨ç†-è¿œç¨‹-policy-server-ä¸æœ¬åœ°-client-å®æ“.html">â† SmolVLA å¼‚æ­¥æ¨ç†ï¼šè¿œç¨‹ Policy Server ä¸æœ¬åœ° Client å®æ“</a>
    <a class="next" href="ä»æ•°å­¦è§’åº¦ç†è§£flow-matchingä¸­çš„çº¿æ€§æ’å€¼.html">ä»æ•°å­¦è§’åº¦ç†è§£flow matchingä¸­çš„çº¿æ€§æ’å€¼ â†’</a>
  </div>
</article>

      </section>

      <aside class="right-panel">
        
      </aside>
    </main>

    <footer class="site-footer">
      <div class="container">Copyright Â©2022-2025 laumy ç‰ˆæƒæ‰€æœ‰</div>
    </footer>

    <script src="assets/site.js"></script>
  </body>
  </html>

