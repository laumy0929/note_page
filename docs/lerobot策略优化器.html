<!doctype html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>lerobotç­–ç•¥ä¼˜åŒ–å™¨ - Laumyçš„æŠ€æœ¯æ ˆ</title>
    <link rel="stylesheet" href="assets/style.css">
    <!-- MathJaxæ”¯æŒLaTeXæ•°å­¦å…¬å¼ -->
    <script>
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          displayMath: [['$$', '$$'], ['\\[', '\\]']],
          processEscapes: true,
          processEnvironments: true
        },
        options: {
          ignoreHtmlClass: 'tex2jax_ignore',
          processHtmlClass: 'tex2jax_process'
        }
      };
    </script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body>
    <header class="site-header">
      <div class="container">
        <a class="logo" href="./">Laumyçš„æŠ€æœ¯æ ˆ</a>
        <div class="search">
          <input id="search-input" type="text" placeholder="è¾“å…¥å…³é”®è¯å›è½¦æœç´¢">
        </div>
        <div class="theme-toggle" title="åˆ‡æ¢ä¸»é¢˜" id="theme-toggle">â˜¾</div>
        <nav class="top-nav">
          <div class="nav-item"><a href="./">é¦–é¡µ</a></div>
          <div class="nav-item site-link">
            <a href="https://www.laumy.tech" target="_blank" title="è®¿é—®ä¸»ç«™">ä¸»ç«™ç‚¹:www.laumy.tech</a>
          </div>
        </nav>
      </div>
    </header>

    <main class="container layout">
      <aside class="left-nav">
        
        <div class="card">
          <div class="card-title">æ–‡ç« ç›®å½•</div>
          <nav id="toc"><ul><li><a href="#torchoptim">torch.optimç®€ä»‹</a><ul><li><a href="#_1">ä»€ä¹ˆä¼˜åŒ–å™¨</a></li><li><a href="#torchoptim_1">torch.optimæ€ä¹ˆç”¨</a></li></ul></li><li><a href="#optimizerconfig">æŠ½è±¡åŸºç±»OptimizerConfig</a><ul><li><a href="#_2">ç»§æ‰¿å…³ç³»</a></li><li><a href="#_3">æ ¸å¿ƒå±æ€§</a></li><li><a href="#_4">æ ¸å¿ƒæ–¹æ³•</a></li></ul></li><li><a href="#_5">å®ä¾‹åŒ–å­ç±»</a><ul><li><a href="#_6">å•å‚æ•°ä¼˜åŒ–å™¨</a></li><li><a href="#_7">å¤šå‚æ•°ä¼˜åŒ–å™¨</a></li></ul></li><li><a href="#_8">ä¼˜åŒ–å™¨çŠ¶æ€ç®¡ç†</a><ul><li><a href="#_9">çŠ¶æ€ä¿å­˜</a></li><li><a href="#_10">çŠ¶æ€åŠ è½½</a></li></ul></li><li><a href="#_11">å·¥ç¨‹è°ƒç”¨</a><ul><li><a href="#_12">åˆ›å»ºæµç¨‹</a></li><li><a href="#_13">è®­ç»ƒæµç¨‹</a></li></ul></li></ul></nav>
        </div>
        
      </aside>

      <section class="content">
        
<article class="card post">
  <h1>lerobotç­–ç•¥ä¼˜åŒ–å™¨</h1>
  <div class="meta">
    <span class="meta-item">
      <i class="icon">ğŸ•’</i>
      2025-08-02
    </span>
    <span class="meta-item">
      <i class="icon">ğŸ“‚</i>
      ai
    </span>
    <span class="meta-item">
      <i class="icon">ğŸ‘¤</i>
      laumy
    </span>
  </div>
  <div class="post-content"><h2 id="torchoptim">torch.optimç®€ä»‹</h2>
<p>åœ¨å­¦æ ¡lerobotçš„ç­–ç•¥ä¼˜åŒ–å™¨å‰ï¼Œæˆ‘ä»¬å…ˆå†å¤ä¹ ä¸€ä¸‹ä»€ä¹ˆæ˜¯ä¼˜åŒ–å™¨ã€‚</p>
<h3 id="_1">ä»€ä¹ˆä¼˜åŒ–å™¨</h3>
<p>ä¼˜åŒ–å™¨å®˜æ–¹è§£é‡Šå°±æ˜¯åœ¨æ·±åº¦å­¦ä¹ ä¸­è®©æŸå¤±å‡½æ•°é€šè¿‡æ¢¯åº¦ä¸‹é™æ€æƒ³é€æ­¥è°ƒæ•´å‚æ•°ä»¥è¾¾åˆ°æœ€å°æŸå¤±ã€‚</p>
<p>ç®€å•ç†è§£ä¼˜åŒ–å™¨çš„å°±æ˜¯æ›´æ–°è®¡ç®—å‚æ•°çš„ï¼Œæ ¹æ®æŸå¤±å‡½æ•°çš„æ¢¯åº¦æ–¹å‘è°ƒæ•´æ¨¡å‹æƒé‡å’Œåç½®å€¼ï¼Œå…¬å¼ä¸ºï¼šæ–°å‚æ•° = æ—§å‚æ•° - å­¦ä¹ ç‡ Ã— æ¢¯åº¦ã€‚é€šè¿‡è¿­ä»£é€æ­¥é€¼è¿‘æœ€ä¼˜è§£ã€‚åœ¨æ–‡ç« <a href="https://www.laumy.tech/2050.html">https://www.laumy.tech/2050.html</a>æˆ‘ä»¬å·²ç»æ¢è®¨è¿‡å¸¸ç”¨çš„ä¼˜åŒ–ç®—æ³•ã€‚</p>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬å†æ¥ä»PyTorchä½¿ç”¨çš„è§’åº¦å¤ä¹ ä¸€ä¸‹ã€‚torch.optim æ˜¯ PyTorch å®˜æ–¹ä¼˜åŒ–å™¨æ¨¡å—ï¼Œæä¾›äº† SGDã€Adamã€AdamW ç­‰ä¸»æµä¼˜åŒ–ç®—æ³•çš„å®ç°ï¼Œæ‰€æœ‰çš„ä¼˜åŒ–å™¨éƒ½ç»§æ‰¿è‡ªåŸºç±» torch.optim.Optimizerã€‚å…¶æ ¸å¿ƒä½œç”¨æ˜¯å¦‚ä¸‹ï¼š</p>
<ul>
<li>è‡ªåŠ¨åŒ–å‚æ•°æ›´æ–°ï¼šæ ¹æ®åå‘ä¼ æ’­è®¡ç®—çš„æ¢¯åº¦ï¼ŒæŒ‰ç‰¹å®šä¼˜åŒ–ç­–ç•¥ï¼ˆå¦‚ Adam çš„è‡ªé€‚åº”å­¦ä¹ ç‡ï¼‰æ›´æ–°æ¨¡å‹å‚æ•°ã€‚</li>
<li>ç»Ÿä¸€æ¥å£æŠ½è±¡ï¼šé€šè¿‡ Optimizer åŸºç±»å°è£…ä¸åŒç®—æ³•ï¼Œæä¾›ä¸€è‡´çš„ä½¿ç”¨æµç¨‹ï¼ˆzero_grad() æ¸…ç©ºæ¢¯åº¦ â†’ step() æ›´æ–°å‚æ•°ï¼‰ã€‚</li>
</ul>
<p>åœ¨Pytorchä¸­ä¼˜åŒ–å™¨ç»Ÿä¸€å°è£…æˆtorch.optimæ¥å£è°ƒç”¨ï¼Œå¯ä»¥æœ‰ä»¥ä¸‹ä¼˜åŠ¿ã€‚</p>
<ul>
<li>é¿å…é‡å¤å®ç°å¤æ‚ç®—æ³•ï¼šæ— éœ€æ‰‹åŠ¨ç¼–å†™ Adam çš„åŠ¨é‡ã€äºŒé˜¶çŸ©ä¼°è®¡ç­‰é€»è¾‘ï¼Œç›´æ¥è°ƒç”¨æˆç†Ÿæ¥å£ã€‚</li>
<li>çµæ´»æ”¯æŒè®­ç»ƒéœ€æ±‚ï¼šæ”¯æŒå•/å¤šå‚æ•°ç»„ä¼˜åŒ–ï¼ˆå¦‚ä¸åŒæ¨¡å—ç”¨ä¸åŒå­¦ä¹ ç‡ï¼‰ã€å­¦ä¹ ç‡è°ƒåº¦ã€æ¢¯åº¦æ¸…é›¶ç­‰æ ¸å¿ƒè®­ç»ƒé€»è¾‘ã€‚</li>
<li>å·¥ç¨‹åŒ–ä¸å¯ç»´æŠ¤æ€§ï¼šé€šè¿‡ç»Ÿä¸€æ¥å£ç®¡ç†è¶…å‚æ•°ï¼ˆlrã€weight_decayï¼‰ï¼Œä¾¿äºå®éªŒå¯¹æ¯”ä¸ä»£ç å¤ç”¨ã€‚</li>
</ul>
<h3 id="torchoptim_1">torch.optimæ€ä¹ˆç”¨</h3>
<p><strong>Step 1ï¼šå®šä¹‰æ¨¡å‹ä¸ä¼˜åŒ–å™¨</strong></p>
<div class="codehilite"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>

<span class="c1"># 1. å®šä¹‰æ¨¡å‹ï¼ˆç¤ºä¾‹ï¼šç®€å•çº¿æ€§å±‚ï¼‰</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># 2. åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼šä¼ å…¥æ¨¡å‹å‚æ•° + è¶…å‚æ•°</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
    <span class="n">params</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>  <span class="c1"># å¾…ä¼˜åŒ–å‚æ•°ï¼ˆPyTorch å‚æ•°è¿­ä»£å™¨ï¼‰</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>                    <span class="c1"># å­¦ä¹ ç‡ï¼ˆæ ¸å¿ƒè¶…å‚æ•°ï¼‰</span>
    <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span>         <span class="c1"># Adam åŠ¨é‡å‚æ•°ï¼ˆæ§åˆ¶å†å²æ¢¯åº¦å½±å“ï¼‰</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span>           <span class="c1"># æƒé‡è¡°å‡ï¼ˆL2 æ­£åˆ™åŒ–ï¼Œå¯é€‰ï¼‰</span>
<span class="p">)</span>
</code></pre></div>
<p>å®šä¹‰äº†ä¸€ä¸ªoptimizerä½¿ç”¨çš„æ˜¯Adamä¼˜åŒ–å™¨ï¼Œè¯¥ä¼˜åŒ–å™¨å­¦ä¹ ç‡è®¾ç½®ä¸º1e-3ï¼Œæƒé‡è¡°å‡ä¸º0.01ã€‚</p>
<p><strong>Step 2ï¼šè®­ç»ƒå¾ªç¯</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># æ¨¡æ‹Ÿè¾“å…¥æ•°æ®ï¼ˆbatch_size=32ï¼Œç‰¹å¾ç»´åº¦=10ï¼‰</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">targets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># æ¨¡æ‹Ÿç›®æ ‡å€¼</span>

<span class="c1"># è®­ç»ƒå¾ªç¯</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># â‘  æ¸…ç©ºè¿‡å¾€æ¢¯åº¦ï¼ˆå¿…é¡»ï¼å¦åˆ™æ¢¯åº¦ç´¯ç§¯å¯¼è‡´æ›´æ–°å¼‚å¸¸ï¼‰</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># â‘¡ å‰å‘ä¼ æ’­ + è®¡ç®—æŸå¤±</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>  <span class="c1"># å‡æ–¹è¯¯å·®æŸå¤±</span>

    <span class="c1"># â‘¢ åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦ + ä¼˜åŒ–å™¨æ›´æ–°å‚æ•°</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># è‡ªåŠ¨è®¡ç®—æ‰€æœ‰å¯è®­ç»ƒå‚æ•°çš„æ¢¯åº¦</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># æ ¹æ®æ¢¯åº¦æ›´æ–°å‚æ•°</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">, Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</code></pre></div>
<p>lossæ˜¯æŸå¤±ï¼Œé€šè¿‡è°ƒç”¨loss.backward()è¿›è¡Œåå‘ä¼ æ’­Pytorchå°±è‡ªåŠ¨æŠŠæ¢¯åº¦è®¡ç®—å¥½ä¿å­˜äº†ï¼Œç„¶åè°ƒç”¨å…³é”®çš„ä¸€éƒ¨optimizer.step()å°±å¯ä»¥æ‰§è¡Œå‚æ•°æ›´æ–°äº†ï¼ˆå³æ–°å‚æ•°=æ—§å‚æ•°-å­¦ä¹ ç‡*æ¢¯åº¦ï¼‰ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨è°ƒç”¨loss.backward()è¿›è¡Œåå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦æ—¶ï¼Œè¦å…ˆè°ƒç”¨optimizer.zero_grad()æŠŠä¹‹å‰çš„æ¢¯åº¦å€¼æƒ…å†µï¼Œå› æ­¤æ¯è®¡ç®—ä¸€æ¬¡æ¢¯åº¦éƒ½æ˜¯è¢«ä¿å­˜ï¼Œä¸æƒ…å†µä¼šå¯¼è‡´æ¢¯åº¦ç´¯ç§¯ã€‚</p>
<p><strong>Step 3ï¼šå·®å¼‚åŒ–ä¼˜åŒ–å‚æ•°åˆ†ç»„</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># å®šä¹‰å‚æ•°ç»„ï¼ˆä¸åŒæ¨¡å—ç”¨ä¸åŒå­¦ä¹ ç‡ï¼‰</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">([</span>
    <span class="p">{</span>
        <span class="s2">"params"</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">backbone</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>  <span class="c1"># backbone å‚æ•°</span>
        <span class="s2">"lr"</span><span class="p">:</span> <span class="mf">1e-5</span>  <span class="c1"># å°å­¦ä¹ ç‡å¾®è°ƒ</span>
    <span class="p">},</span>
    <span class="p">{</span>
        <span class="s2">"params"</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>       <span class="c1"># ä»»åŠ¡å¤´å‚æ•°</span>
        <span class="s2">"lr"</span><span class="p">:</span> <span class="mf">1e-3</span>  <span class="c1"># å¤§å­¦ä¹ ç‡æ›´æ–°</span>
    <span class="p">}</span>
<span class="p">],</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">))</span>  <span class="c1"># å…¬å…±è¶…å‚æ•°ï¼ˆæ‰€æœ‰ç»„å…±äº«ï¼‰</span>
</code></pre></div>
<p>ä¸Šé¢æ˜¯é’ˆå¯¹åŒä¸€ä¸ªæ¨¡å‹å†…ä¸åŒæ¨¡å—ä½¿ç”¨ä¸åŒçš„è¶…å‚æ•°lrã€‚</p>
<h2 id="optimizerconfig">æŠ½è±¡åŸºç±»OptimizerConfig</h2>
<p>OptimizerConfig æ˜¯æ‰€æœ‰ä¼˜åŒ–å™¨é…ç½®çš„æŠ½è±¡åŸºç±»ï¼Œé€šè¿‡ draccus.ChoiceRegistry å®ç°å­ç±»æ³¨å†Œæœºåˆ¶ï¼ˆç±»ä¼¼æ’ä»¶ç³»ç»Ÿï¼‰ï¼Œä¸ºæ–°å¢ä¼˜åŒ–å™¨ç±»å‹æä¾›ç»Ÿä¸€æ¥å£ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">OptimizerConfig</span><span class="p">(</span><span class="n">draccus</span><span class="o">.</span><span class="n">ChoiceRegistry</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span>
    <span class="n">grad_clip_norm</span><span class="p">:</span> <span class="nb">float</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_choice_name</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">default_choice_name</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">"adam"</span>

    <span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
<h3 id="_2">ç»§æ‰¿å…³ç³»</h3>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">OptimizerConfig</span><span class="p">(</span><span class="n">draccus</span><span class="o">.</span><span class="n">ChoiceRegistry</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">ABC</span><span class="p">):</span>
</code></pre></div>
<p>OptimizerConfig ç»§æ‰¿abc.ABCå’Œdraccus.ChoiceRegistryï¼Œå‰è€…æ ‡è®°ä¸ºæŠ½è±¡åŸºç±»ï¼Œå¼ºåˆ¶å­ç±»å®ç°buildçš„æŠ½è±¡æ–¹æ³•ï¼Œç¡®ä¿æ¥å£çš„ä¸€è‡´æ€§ã€‚åè€…æä¾›å­ç±»æ³¨å†Œæœºåˆ¶ï¼Œé€šè¿‡@OptimizerConfig.register_subclass("åç§°") å°†å­ç±»ä¸ä¼˜åŒ–å™¨ç±»å‹ç»‘å®šï¼ˆå¦‚ "adam" â†’ AdamConfigï¼‰ï¼Œæ”¯æŒé…ç½®é©±åŠ¨çš„åŠ¨æ€å®ä¾‹åŒ–ã€‚</p>
<h3 id="_3">æ ¸å¿ƒå±æ€§</h3>
<div class="codehilite"><pre><span></span><code><span class="n">lr</span><span class="p">:</span> <span class="nb">float</span>                  <span class="c1"># å­¦ä¹ ç‡ï¼ˆæ ¸å¿ƒè¶…å‚æ•°ï¼‰</span>
<span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span>        <span class="c1"># æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ç³»æ•°ï¼‰</span>
<span class="n">grad_clip_norm</span><span class="p">:</span> <span class="nb">float</span>      <span class="c1"># æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰</span>
</code></pre></div>
<p>ä¸Šé¢3ä¸ªå‚æ•°éƒ½æ˜¯ä¼˜åŒ–å™¨çš„åŸºç¡€é…ç½®ï¼Œé¿å…å­ç±»é‡å¤å®šä¹‰ã€‚</p>
<ul>
<li>lr/weight_decayï¼šç›´æ¥ä¼ é€’ç»™ torch.optim ä¼˜åŒ–å™¨ï¼ˆå¦‚ Adam çš„ lr å‚æ•°ï¼‰</li>
<li>grad_clip_normï¼šä¸å‚ä¸ä¼˜åŒ–å™¨åˆ›å»ºï¼Œè€Œæ˜¯åœ¨è®­ç»ƒæµç¨‹ä¸­ç”¨äºæ¢¯åº¦è£å‰ªï¼ˆå¦‚ train.py ä¸­ torch.nn.utils.clip_grad_norm_ï¼‰</li>
</ul>
<h3 id="_4">æ ¸å¿ƒæ–¹æ³•</h3>
<p><strong>ï¼ˆ1ï¼‰typeå±æ€§ç”¨äºè¡¨ç¤ºä¼˜åŒ–å™¨ç±»å‹</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nd">@property</span>
<span class="k">def</span> <span class="nf">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_choice_name</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">)</span>
</code></pre></div>
<p>é€šè¿‡ draccus.ChoiceRegistry çš„ get_choice_name æ–¹æ³•ï¼Œè·å–å­ç±»æ³¨å†Œçš„ä¼˜åŒ–å™¨ç±»å‹åç§°ï¼ˆå¦‚ AdamConfig çš„ type ä¸º "adam"ï¼‰ã€‚</p>
<p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåœ¨é…ç½®è§£ææ—¶ï¼Œé€šè¿‡ type å­—æ®µï¼ˆå¦‚ {"type": "adam"}ï¼‰å³å¯åŒ¹é…åˆ°å¯¹åº”å­ç±»ï¼ˆAdamConfigï¼‰ï¼Œå®ç°â€œé…ç½®â†’å®ä¾‹â€çš„è‡ªåŠ¨æ˜ å°„ã€‚</p>
<p><strong>ï¼ˆ2ï¼‰default_choice_nameé»˜è®¤ä¼˜åŒ–å™¨ç±»å‹</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">default_choice_name</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span> <span class="o">|</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="s2">"adam"</span>
</code></pre></div>
<p>å½“é…ç½®ä¸­ä¸ºæ˜¾å¼æŒ‡å®štypeæ—¶ï¼Œé»˜è®¤æ˜¯ç”¨adamç±»å‹å³AdamConfigï¼Œæ—¨åœ¨ç®€åŒ–ç”¨æˆ·é…ç½®ï¼Œæ— éœ€æ‰‹åŠ¨æŒ‡å®šå¸¸è§ä¼˜åŒ–å™¨ç±»å‹ã€‚</p>
<p><strong>ï¼ˆ3ï¼‰buildæŠ½è±¡æ¥å£ï¼Œä¼˜åŒ–å™¨åˆ›å»ºæ¥å£</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nd">@abc</span><span class="o">.</span><span class="n">abstractmethod</span>
<span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">"""Build the optimizer. It can be a single optimizer or a dictionary of optimizers."""</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</code></pre></div>
<p>å¼ºåˆ¶å­ç±»å®ç°buildçš„æ–¹æ³•ã€‚</p>
<h2 id="_5">å®ä¾‹åŒ–å­ç±»</h2>
<p>optimizers.pyä¸­ä¸€å…±å®šä¹‰äº†4ç§ä¼˜åŒ–å™¨é…ç½®å­ç±»ï¼Œadamï¼Œadamwï¼Œsgdï¼Œ multi_adamï¼Œå…¶ä¸­å‰3ä¸ªæ˜¯å•å‚æ•°ä¼˜åŒ–å™¨ï¼Œæœ€åä¸€ä¸ªæ˜¯å¤šå‚æ•°ä¼˜åŒ–å™¨ï¼Œæœ€ç»ˆå‡é€šè¿‡buildæ–¹æ³•åˆ›å»ºtorch.optimå®ä¾‹</p>
<h3 id="_6">å•å‚æ•°ä¼˜åŒ–å™¨</h3>
<div class="codehilite"><pre><span></span><code><span class="nd">@OptimizerConfig</span><span class="o">.</span><span class="n">register_subclass</span><span class="p">(</span><span class="s2">"adam"</span><span class="p">)</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">AdamConfig</span><span class="p">(</span><span class="n">OptimizerConfig</span><span class="p">):</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span>
    <span class="n">betas</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
    <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-8</span>
    <span class="n">weight_decay</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">grad_clip_norm</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>  <span class="c1"># å°† dataclass å­—æ®µè½¬ä¸ºå­—å…¸</span>
        <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"grad_clip_norm"</span><span class="p">)</span>  <span class="c1"># ç§»é™¤æ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼ˆéä¼˜åŒ–å™¨å‚æ•°ï¼‰</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>  <span class="c1"># åˆ›å»º PyTorch Adam å®ä¾‹</span>
</code></pre></div>
<p>AdamConfig æ˜¯ OptimizerConfig çš„æ ¸å¿ƒå­ç±»ï¼Œå°è£…äº† Adam ä¼˜åŒ–å™¨çš„é…ç½®ä¸å®ä¾‹åŒ–é€»è¾‘ï¼Œé€šè¿‡ draccus æ³¨å†Œæœºåˆ¶ä¸å·¥ç¨‹è®­ç»ƒæµç¨‹æ·±åº¦é›†æˆã€‚</p>
<p>@OptimizerConfig.register_subclass("adam")å°† AdamConfig ç±»ä¸å­—ç¬¦ä¸² "adam" ç»‘å®šï¼Œå®ç° é…ç½®é©±åŠ¨çš„åŠ¨æ€å®ä¾‹åŒ–ï¼Œå½“é…ç½®æ–‡ä»¶ä¸­ optimizer.type: "adam" æ—¶ï¼Œdraccus ä¼šè‡ªåŠ¨è§£æå¹¶å®ä¾‹åŒ– AdamConfigã€‚ç»§æ‰¿è‡ª OptimizerConfig çš„ ChoiceRegistry æœºåˆ¶ï¼Œç¡®ä¿å­ç±»å¯é€šè¿‡ type å­—æ®µè¢«å”¯ä¸€æ ‡è¯†ã€‚</p>
<p>@dataclassè‡ªåŠ¨ç”Ÿæˆ <strong>init</strong>ã€<strong>repr</strong> ç­‰æ–¹æ³•ï¼Œç®€åŒ–è¶…å‚æ•°ç®¡ç†ï¼Œæ— éœ€æ‰‹åŠ¨ç¼–å†™æ„é€ å‡½æ•°ï¼Œç›´æ¥é€šè¿‡ç±»å­—æ®µå®šä¹‰è¶…å‚æ•°ï¼ˆå¦‚ lr=1e-3ï¼‰ã€‚</p>
<p>åœ¨AdamConfigä¸­é»˜è®¤åˆå§‹åŒ–äº†ä¸€äº›å‚æ•°å€¼ï¼Œå…¶ä¸­lrã€betasã€epsã€weight_decayç›´æ¥å¯¹åº” torch.optim.Adam çš„å‚æ•°ï¼Œé€šè¿‡ build æ–¹æ³•ä¼ é€’ç»™ PyTorch ä¼˜åŒ–å™¨ï¼Œè€Œgrad_clip_normä¸å‚ä¸ä¼˜åŒ–å™¨åˆ›å»ºï¼Œè€Œæ˜¯ç”¨äºè®­ç»ƒæ—¶çš„æ¢¯åº¦è£å‰ªï¼ˆå¦‚ train.py ä¸­ torch.nn.utils.clip_grad_norm_ï¼‰ï¼Œå®ç°â€œä¼˜åŒ–å™¨å‚æ•°â€ä¸â€œè®­ç»ƒæµç¨‹å‚æ•°â€çš„èŒè´£åˆ†ç¦»ã€‚</p>
<p>åœ¨æœ€åçš„buildæ–¹æ³•ä¸­ï¼Œè°ƒç”¨torch.optim.Adam(params, **kwargs) å®ä¾‹åŒ–ä¼˜åŒ–å™¨ã€‚åœ¨æ­¤ä¹‹å‰ï¼Œå…ˆè°ƒç”¨asdict(self)å°† AdamConfig å®ä¾‹çš„å­—æ®µï¼ˆå¦‚ lrã€betasï¼‰è½¬æ¢ä¸ºå­—å…¸ {"lr": 1e-3, "betas": (0.9, 0.999), ...}ï¼Œå†è°ƒç”¨kwargs.pop("grad_clip_norm")å‰”é™¤ grad_clip_normï¼ˆæ¢¯åº¦è£å‰ªé˜ˆå€¼ï¼‰ï¼Œå› å…¶ä¸å±äºtorch.optim.Adam çš„å‚æ•°ï¼ˆä¼˜åŒ–å™¨ä»…è´Ÿè´£å‚æ•°æ›´æ–°ï¼Œæ¢¯åº¦è£å‰ªæ˜¯è®­ç»ƒæµç¨‹çš„ç‹¬ç«‹æ­¥éª¤ï¼‰ã€‚</p>
<h3 id="_7">å¤šå‚æ•°ä¼˜åŒ–å™¨</h3>
<div class="codehilite"><pre><span></span><code><span class="nd">@OptimizerConfig</span><span class="o">.</span><span class="n">register_subclass</span><span class="p">(</span><span class="s2">"multi_adam"</span><span class="p">)</span>
<span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">MultiAdamConfig</span><span class="p">(</span><span class="n">OptimizerConfig</span><span class="p">):</span>
    <span class="n">optimizer_groups</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default_factory</span><span class="o">=</span><span class="nb">dict</span><span class="p">)</span>  <span class="c1"># ç»„å†…è¶…å‚æ•°</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]:</span>
        <span class="n">optimizers</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">params_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="c1"># åˆå¹¶é»˜è®¤è¶…å‚æ•°ä¸ç»„å†…è¶…å‚æ•°ï¼ˆç»„å†…å‚æ•°ä¼˜å…ˆï¼‰</span>
            <span class="n">group_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_groups</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">{})</span>
            <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">"lr"</span><span class="p">:</span> <span class="n">group_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span>  <span class="c1"># ç»„å†… lr æˆ–é»˜è®¤ lr</span>
                <span class="s2">"betas"</span><span class="p">:</span> <span class="n">group_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"betas"</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)),</span>
                <span class="s2">"weight_decay"</span><span class="p">:</span> <span class="n">group_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"weight_decay"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">),</span>
            <span class="p">}</span>
            <span class="n">optimizers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">**</span><span class="n">optimizer_kwargs</span><span class="p">)</span>  <span class="c1"># ä¸ºæ¯ç»„åˆ›å»ºç‹¬ç«‹ä¼˜åŒ–å™¨</span>
        <span class="k">return</span> <span class="n">optimizers</span>  <span class="c1"># è¿”å›ä¼˜åŒ–å™¨å­—å…¸ï¼š{"backbone": optimizer1, "head": optimizer2, ...}</span>
</code></pre></div>
<p>MultiAdamConfig æ˜¯ OptimizerConfig çš„å…³é”®å­ç±»ï¼Œä¸“ä¸ºå¤šå‚æ•°ç»„ä¼˜åŒ–åœºæ™¯è®¾è®¡ï¼Œæ”¯æŒä¸ºæ¨¡å‹ä¸åŒæ¨¡å—ï¼ˆå¦‚ backbone ä¸ headï¼‰åˆ›å»ºç‹¬ç«‹çš„ Adam ä¼˜åŒ–å™¨ï¼Œå®ç°å·®å¼‚åŒ–è¶…å‚æ•°é…ç½®ã€‚</p>
<p>é¦–å…ˆè·Ÿå‰é¢å•å‚æ•°çš„å±æ€§ä¸åŒç‚¹æ˜¯å¤šäº†ä¸€ä¸ªoptimizer_groupsï¼Œè¿™æ˜¯ä¸€ä¸ªè¶…å‚æ•°å­—å…¸ï¼Œå­˜å‚¨å¤šç»„ä¸åŒçš„è¶…å‚æ•°ï¼Œç¤ºä¾‹å¦‚ä¸‹ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="n">optimizer_groups</span><span class="o">=</span><span class="p">{</span>
    <span class="s2">"backbone"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"lr"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="s2">"weight_decay"</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">},</span>  <span class="c1"># ä½å­¦ä¹ ç‡å¾®è°ƒ backbone</span>
    <span class="s2">"head"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"lr"</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="s2">"betas"</span><span class="p">:</span> <span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)}</span>      <span class="c1"># é«˜å­¦ä¹ ç‡æ›´æ–° headï¼Œè‡ªå®šä¹‰åŠ¨é‡å‚æ•°</span>
<span class="p">}</span>
</code></pre></div>
<p>buildçš„æ–¹æ³•ä¸»è¦é€»è¾‘å¦‚ä¸‹ï¼š</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">list</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]:</span>
    <span class="n">optimizers</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">params_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># 1. è·å–ç»„å†…è¶…å‚æ•°ï¼ˆæ— åˆ™ä½¿ç”¨é»˜è®¤ï¼‰</span>
        <span class="n">group_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer_groups</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">{})</span>
        <span class="c1"># 2. åˆå¹¶é»˜è®¤ä¸ç»„å†…è¶…å‚æ•°</span>
        <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"lr"</span><span class="p">:</span> <span class="n">group_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"lr"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">),</span>
            <span class="s2">"betas"</span><span class="p">:</span> <span class="n">group_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"betas"</span><span class="p">,</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)),</span>
            <span class="s2">"eps"</span><span class="p">:</span> <span class="n">group_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"eps"</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">),</span>
            <span class="s2">"weight_decay"</span><span class="p">:</span> <span class="n">group_config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"weight_decay"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_decay</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="c1"># 3. ä¸ºè¯¥ç»„åˆ›å»º Adam ä¼˜åŒ–å™¨</span>
        <span class="n">optimizers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="o">**</span><span class="n">optimizer_kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizers</span>  <span class="c1"># è¿”å›ï¼š{ç»„å: ä¼˜åŒ–å™¨å®ä¾‹}</span>
</code></pre></div>
<p>å…¶ä¸­params_dictæ˜¯è¶…å‚æ•°ç»„çš„æ¥æºï¼Œæ˜¯å­—å…¸ç±»å‹ï¼Œé”®ä¸ºå‚æ•°ç»„åç§°ï¼ˆéœ€ä¸ optimizer_groups é”®åŒ¹é…ï¼‰ï¼Œå€¼ä¸ºè¯¥ç»„å‚æ•°åˆ—è¡¨ï¼ˆå¦‚æ¨¡å‹æŸæ¨¡å—çš„ parameters()ï¼‰ã€‚é€šå¸¸æ˜¯ç­–ç•¥ç±»çš„get_optim_paramsæ–¹æ³•æä¾›ï¼Œå¦‚ä¸‹ï¼š</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># ç­–ç•¥ç±»ä¸­æ‹†åˆ†å‚æ•°ç»„ï¼ˆç¤ºä¾‹é€»è¾‘ï¼‰</span>
<span class="k">def</span> <span class="nf">get_optim_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">"backbone"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">backbone</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
        <span class="s2">"head"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span>
    <span class="p">}</span>
</code></pre></div>
<p>ä¸»è¦çš„æ ¸å¿ƒé€»è¾‘æ˜¯å¯¹äºæ¯ä¸ªå‚æ•°ç»„ï¼Œä¼˜å…ˆä½¿ç”¨ optimizer_groups ä¸­çš„è¶…å‚æ•°ï¼ˆå¦‚ group_config.get("lr")ï¼‰ï¼Œæ— åˆ™å›é€€åˆ°é»˜è®¤å€¼ï¼ˆå¦‚ self.lrï¼‰ï¼Œç„¶åä¸ºæ¯ä¸ªå‚æ•°ç»„åˆ›å»ºç‹¬ç«‹çš„ torch.optim.Adam å®ä¾‹ï¼Œç¡®ä¿å‚æ•°æ›´æ–°äº’ä¸å¹²æ‰°ã€‚</p>
<h2 id="_8">ä¼˜åŒ–å™¨çŠ¶æ€ç®¡ç†</h2>
<h3 id="_9">çŠ¶æ€ä¿å­˜</h3>
<p>å°†ä¼˜åŒ–å™¨çš„æŸä¸€ä¸ªæ—¶åˆ»å‚æ•°è¿›è¡Œå­˜å‚¨ï¼Œæ–¹ä¾¿è¿‡ç¨‹æŸ¥çœ‹ä»¥åŠé‡æ–°åŠ è½½æ¨¡å‹è®­ç»ƒç­‰ç­‰ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">save_optimizer_state</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">],</span>  <span class="c1"># ä¼˜åŒ–å™¨å®ä¾‹æˆ–å­—å…¸</span>
    <span class="n">save_dir</span><span class="p">:</span> <span class="n">Path</span>  <span class="c1"># æ ¹ä¿å­˜ç›®å½•</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="c1"># 1. å¤„ç†å¤šå‚æ•°ä¼˜åŒ–å™¨å­—å…¸ï¼ˆå¦‚ MultiAdamConfig åˆ›å»ºçš„ä¼˜åŒ–å™¨ï¼‰</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>  <span class="c1"># éå†ä¼˜åŒ–å™¨åç§°ä¸å®ä¾‹ï¼ˆå¦‚ "backbone": opt1ï¼‰</span>
            <span class="n">optimizer_dir</span> <span class="o">=</span> <span class="n">save_dir</span> <span class="o">/</span> <span class="n">name</span>  <span class="c1"># åˆ›å»ºå­ç›®å½•ï¼šæ ¹ç›®å½•/ä¼˜åŒ–å™¨åç§°ï¼ˆå¦‚ save_dir/backboneï¼‰</span>
            <span class="n">optimizer_dir</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># ç¡®ä¿ç›®å½•å­˜åœ¨ï¼ˆå«çˆ¶ç›®å½•åˆ›å»ºï¼‰</span>
            <span class="n">_save_single_optimizer_state</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">optimizer_dir</span><span class="p">)</span>  <span class="c1"># å§”æ‰˜å•ä¼˜åŒ–å™¨ä¿å­˜é€»è¾‘</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 2. å¤„ç†å•å‚æ•°ä¼˜åŒ–å™¨ï¼ˆå¦‚ AdamConfig åˆ›å»ºçš„ä¼˜åŒ–å™¨ï¼‰</span>
        <span class="n">_save_single_optimizer_state</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">)</span>  <span class="c1"># ç›´æ¥ä½¿ç”¨æ ¹ç›®å½•ä¿å­˜</span>
</code></pre></div>
<p>åŒºåˆ†å•å‚æ•°å’Œå¤šå‚æ•°ä¼˜åŒ–å™¨ï¼Œå¯¹åº”å¤šå‚æ•°ä¼˜åŒ–å™¨ä¸ºæ¯ä¸ªä¼˜åŒ–å™¨åˆ›å»ºç‹¬ç«‹å­ç›®å½•ï¼ˆå¦‚ save_dir/backboneã€save_dir/headï¼‰ï¼Œé¿å…ä¸åŒä¼˜åŒ–å™¨çš„çŠ¶æ€æ–‡ä»¶å†²çªã€‚å¦‚æœæ˜¯å•ä¼˜åŒ–å™¨ï¼Œåˆ™ç›´æ¥è°ƒç”¨ _save_single_optimizer_stateï¼ŒçŠ¶æ€æ–‡ä»¶ä¿å­˜äº save_dir æ ¹ç›®å½•ï¼Œç»“æ„ç®€æ´ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">_save_single_optimizer_state</span><span class="p">(</span><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Save a single optimizer's state to disk."""</span>
    <span class="c1"># 1. è·å–ä¼˜åŒ–å™¨å®Œæ•´çŠ¶æ€å­—å…¸ï¼ˆå«å‚æ•°ç»„å’Œå†…éƒ¨çŠ¶æ€ï¼‰</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>

    <span class="c1"># 2. åˆ†ç¦»å‚æ•°ç»„ï¼ˆè¶…å‚æ•°é…ç½®ï¼‰ä¸å‰©ä½™çŠ¶æ€ï¼ˆå¼ é‡æ•°æ®ï¼‰</span>
    <span class="n">param_groups</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"param_groups"</span><span class="p">)</span>  <span class="c1"># å‚æ•°ç»„ï¼šå­¦ä¹ ç‡ã€æƒé‡è¡°å‡ç­‰è¶…å‚æ•°ï¼ˆéå¼ é‡ï¼‰</span>
    <span class="n">flat_state</span> <span class="o">=</span> <span class="n">flatten_dict</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>  <span class="c1"># å‰©ä½™çŠ¶æ€ï¼šåŠ¨é‡ã€äºŒé˜¶çŸ©ç­‰å¼ é‡ï¼ˆå±•å¹³åµŒå¥—å­—å…¸ï¼Œä¾¿äºåºåˆ—åŒ–ï¼‰</span>

    <span class="c1"># 3. ä¿å­˜å¼ é‡çŠ¶æ€ï¼ˆsafetensorsï¼‰ä¸å‚æ•°ç»„ï¼ˆJSONï¼‰</span>
    <span class="n">save_file</span><span class="p">(</span><span class="n">flat_state</span><span class="p">,</span> <span class="n">save_dir</span> <span class="o">/</span> <span class="n">OPTIMIZER_STATE</span><span class="p">)</span>  <span class="c1"># å¼ é‡æ•°æ®ï¼šé«˜æ•ˆäºŒè¿›åˆ¶å­˜å‚¨ï¼ˆå¦‚ "optimizer_state.safetensors"ï¼‰</span>
    <span class="n">write_json</span><span class="p">(</span><span class="n">param_groups</span><span class="p">,</span> <span class="n">save_dir</span> <span class="o">/</span> <span class="n">OPTIMIZER_PARAM_GROUPS</span><span class="p">)</span>  <span class="c1"># å‚æ•°ç»„ï¼šJSON æ ¼å¼ï¼ˆå¦‚ "optimizer_param_groups.json"æ–¹ä¾¿å¯è§†åŒ–æŸ¥çœ‹ï¼‰</span>
</code></pre></div>
<p>å­˜å‚¨å¼ é‡å’Œéå¼ é‡çš„æ ¼å¼</p>
<ul>
<li>param_groupsï¼šåŒ…å«ä¼˜åŒ–å™¨çš„è¶…å‚æ•°é…ç½®ï¼ˆå¦‚ lrã€weight_decayã€betasï¼‰ï¼Œæ˜¯åˆ—è¡¨åµŒå¥—å­—å…¸çš„ç»“æ„ï¼Œå­˜å‚¨ä¸ºJSONæ ¼å¼ï¼ŒJSON åºåˆ—åŒ–åå¯ç›´æ¥æŸ¥çœ‹è¶…å‚æ•°ï¼Œä¾¿äºè®­ç»ƒè¿‡ç¨‹è¿½æº¯ã€‚å…¶æ–‡ä»¶åä¸ºoptimizer_param_groups.jsonã€‚</li>
<li>stateï¼šåŒ…å«ä¼˜åŒ–å™¨çš„å†…éƒ¨çŠ¶æ€å¼ é‡ï¼ˆå¦‚ Adam çš„ exp_avgã€exp_avg_sq åŠ¨é‡ç¼“å†²åŒºï¼‰ï¼Œæ˜¯åµŒå¥—å­—å…¸ç»“æ„ï¼Œé€šè¿‡ flatten_dict å±•å¹³åç”¨ safetensors ä¿å­˜ï¼Œsafetensorsä¸“ä¸ºå¼ é‡è®¾è®¡çš„å­˜å‚¨æ ¼å¼ï¼Œæ”¯æŒé«˜æ•ˆè¯»å†™ã€å†…å­˜æ˜ å°„ï¼Œé¿å… PyTorch torch.save çš„ pickle å…¼å®¹æ€§é—®é¢˜ã€‚å…¶æ–‡ä»¶åä¸ºoptimizer_state.safetensorsã€‚</li>
</ul>
<h3 id="_10">çŠ¶æ€åŠ è½½</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">load_optimizer_state</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">],</span>  <span class="c1"># å¾…æ¢å¤çš„ä¼˜åŒ–å™¨ï¼ˆå•å®ä¾‹æˆ–å­—å…¸ï¼‰</span>
    <span class="n">save_dir</span><span class="p">:</span> <span class="n">Path</span>  <span class="c1"># çŠ¶æ€æ–‡ä»¶æ ¹ç›®å½•</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span> <span class="o">|</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="c1"># 1. å¤„ç†å¤šä¼˜åŒ–å™¨å­—å…¸ï¼ˆå¦‚ MultiAdamConfig åˆ›å»ºçš„ä¼˜åŒ–å™¨ï¼‰</span>
        <span class="n">loaded_optimizers</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">opt</span> <span class="ow">in</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>  <span class="c1"># éå†ä¼˜åŒ–å™¨åç§°ä¸å®ä¾‹ï¼ˆå¦‚ "backbone": opt1ï¼‰</span>
            <span class="n">optimizer_dir</span> <span class="o">=</span> <span class="n">save_dir</span> <span class="o">/</span> <span class="n">name</span>  <span class="c1"># å­ç›®å½•è·¯å¾„ï¼šæ ¹ç›®å½•/ä¼˜åŒ–å™¨åç§°ï¼ˆå¦‚ save_dir/backboneï¼‰</span>
            <span class="k">if</span> <span class="n">optimizer_dir</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>  <span class="c1"># ä»…å½“ç›®å½•å­˜åœ¨æ—¶åŠ è½½ï¼ˆé¿å…æ–°å¢ä¼˜åŒ–å™¨æ—¶å‡ºé”™ï¼‰</span>
                <span class="n">loaded_optimizers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">_load_single_optimizer_state</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="n">optimizer_dir</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loaded_optimizers</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">opt</span>  <span class="c1"># ç›®å½•ä¸å­˜åœ¨æ—¶è¿”å›åŸä¼˜åŒ–å™¨</span>
        <span class="k">return</span> <span class="n">loaded_optimizers</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 2. å¤„ç†å•ä¼˜åŒ–å™¨ï¼ˆå¦‚ AdamConfig åˆ›å»ºçš„ä¼˜åŒ–å™¨ï¼‰</span>
        <span class="k">return</span> <span class="n">_load_single_optimizer_state</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">)</span>  <span class="c1"># ç›´æ¥ä»æ ¹ç›®å½•åŠ è½½</span>
</code></pre></div>
<p>åŒæ ·æ˜¯åŒºåˆ†å•å‚æ•°å’Œå¤šå‚æ•°ï¼Œå¯¹äºå¤šå‚æ•°ç»„æ ¹æ®save_dir / name å®šä½æ¯ä¸ªä¼˜åŒ–å™¨çš„ç‹¬ç«‹å­ç›®å½•ï¼ˆä¸ save_optimizer_state çš„ä¿å­˜ç»“æ„å¯¹åº”ï¼‰ï¼Œå¦‚æœæ˜¯å•å‚æ•°ä¼˜åŒ–å™¨ç›´æ¥è°ƒç”¨ _load_single_optimizer_stateï¼Œä» save_dir æ ¹ç›®å½•åŠ è½½çŠ¶æ€æ–‡ä»¶ã€‚</p>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">_load_single_optimizer_state</span><span class="p">(</span><span class="n">optimizer</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">:</span> <span class="n">Path</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""Load a single optimizer's state from disk."""</span>
    <span class="c1"># 1. è·å–å½“å‰ä¼˜åŒ–å™¨çš„çŠ¶æ€å­—å…¸ç»“æ„ï¼ˆç”¨äºæ ¡éªŒä¸é€‚é…ï¼‰</span>
    <span class="n">current_state_dict</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>

    <span class="c1"># 2. åŠ è½½å¹¶æ¢å¤å¼ é‡çŠ¶æ€ï¼ˆsafetensors â†’ åµŒå¥—å­—å…¸ï¼‰</span>
    <span class="n">flat_state</span> <span class="o">=</span> <span class="n">load_file</span><span class="p">(</span><span class="n">save_dir</span> <span class="o">/</span> <span class="n">OPTIMIZER_STATE</span><span class="p">)</span>  <span class="c1"># åŠ è½½å±•å¹³çš„å¼ é‡çŠ¶æ€ï¼ˆå¦‚ "optimizer_state.safetensors"ï¼‰</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">unflatten_dict</span><span class="p">(</span><span class="n">flat_state</span><span class="p">)</span>  <span class="c1"># æ¢å¤ä¸ºåµŒå¥—å­—å…¸ï¼ˆä¸ä¿å­˜æ—¶çš„ flatten_dict å¯¹åº”ï¼‰</span>

    <span class="c1"># 3. å¤„ç†ä¼˜åŒ–å™¨å†…éƒ¨çŠ¶æ€ï¼ˆå¦‚åŠ¨é‡ç¼“å†²åŒºï¼‰</span>
    <span class="k">if</span> <span class="s2">"state"</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
        <span class="c1"># å°†å­—ç¬¦ä¸²é”®è½¬ä¸ºæ•´æ•°ï¼ˆsafetensors ä¿å­˜æ—¶é”®ä¸ºå­—ç¬¦ä¸²ï¼ŒPyTorch æœŸæœ›å‚æ•°ç´¢å¼•ä¸ºæ•´æ•°ï¼‰</span>
        <span class="n">loaded_state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"state"</span><span class="p">:</span> <span class="p">{</span><span class="nb">int</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state</span><span class="p">[</span><span class="s2">"state"</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">()}}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">loaded_state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"state"</span><span class="p">:</span> <span class="p">{}}</span>  <span class="c1"># æ–°åˆ›å»ºçš„ä¼˜åŒ–å™¨å¯èƒ½æ— çŠ¶æ€ï¼Œåˆå§‹åŒ–ä¸ºç©º</span>

    <span class="c1"># 4. å¤„ç†å‚æ•°ç»„ï¼ˆè¶…å‚æ•°é…ç½®ï¼Œå¦‚å­¦ä¹ ç‡ã€æƒé‡è¡°å‡ï¼‰</span>
    <span class="k">if</span> <span class="s2">"param_groups"</span> <span class="ow">in</span> <span class="n">current_state_dict</span><span class="p">:</span>
        <span class="c1"># ä» JSON ååºåˆ—åŒ–å‚æ•°ç»„ï¼Œå¹¶ç¡®ä¿ç»“æ„ä¸å½“å‰ä¼˜åŒ–å™¨åŒ¹é…</span>
        <span class="n">param_groups</span> <span class="o">=</span> <span class="n">deserialize_json_into_object</span><span class="p">(</span>
            <span class="n">save_dir</span> <span class="o">/</span> <span class="n">OPTIMIZER_PARAM_GROUPS</span><span class="p">,</span>  <span class="c1"># åŠ è½½å‚æ•°ç»„ JSON æ–‡ä»¶ï¼ˆå¦‚ "optimizer_param_groups.json"ï¼‰</span>
            <span class="n">current_state_dict</span><span class="p">[</span><span class="s2">"param_groups"</span><span class="p">]</span>  <span class="c1"># ä»¥å½“å‰å‚æ•°ç»„ç»“æ„ä¸ºæ¨¡æ¿ï¼Œç¡®ä¿å…¼å®¹æ€§</span>
        <span class="p">)</span>
        <span class="n">loaded_state_dict</span><span class="p">[</span><span class="s2">"param_groups"</span><span class="p">]</span> <span class="o">=</span> <span class="n">param_groups</span>

    <span class="c1"># 5. å°†æ¢å¤çš„çŠ¶æ€å­—å…¸åŠ è½½åˆ°ä¼˜åŒ–å™¨</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">loaded_state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">optimizer</span>
</code></pre></div>
<p>å¼ é‡çš„çŠ¶æ€æ¢å¤éƒ¨åˆ†ï¼Œé€šè¿‡ unflatten_dict å°†ä¿å­˜æ—¶å±•å¹³çš„çŠ¶æ€ï¼ˆflatten_dictï¼‰æ¢å¤ä¸ºåµŒå¥—å­—å…¸ï¼ŒåŒ¹é… PyTorch ä¼˜åŒ–å™¨çŠ¶æ€çš„åŸå§‹ç»“æ„ã€‚æ¥ç€é€šè¿‡state["state"] çš„é”®åœ¨ä¿å­˜æ—¶è¢«åºåˆ—åŒ–ä¸ºå­—ç¬¦ä¸²ï¼ˆå¦‚ "0"ï¼‰ï¼ŒåŠ è½½æ—¶éœ€è½¬å›æ•´æ•°ï¼ˆå¦‚ 0ï¼‰ï¼Œä»¥åŒ¹é… PyTorch å‚æ•°ç´¢å¼•çš„æ•´æ•°ç±»å‹ã€‚</p>
<p>å¯¹äºå‚æ•°ç»„æ¢å¤å…ˆé€šè¿‡JSON ååºåˆ—åŒ–ï¼Œdeserialize_json_into_object å°† JSON æ–‡ä»¶ä¸­çš„å‚æ•°ç»„é…ç½®ï¼ˆå¦‚ [{"lr": 1e-3, ...}, ...]ï¼‰ååºåˆ—åŒ–ä¸º Python å¯¹è±¡ã€‚å†ä»¥å½“å‰ä¼˜åŒ–å™¨çš„ current_state_dict["param_groups"] ä¸ºæ¨¡æ¿ï¼Œç¡®ä¿åŠ è½½çš„å‚æ•°ç»„ä¸å½“å‰ä¼˜åŒ–å™¨çš„å‚æ•°ç»“æ„å…¼å®¹ï¼ˆå¦‚å‚æ•°ç»„æ•°é‡ã€è¶…å‚æ•°å­—æ®µåŒ¹é…ï¼‰ï¼Œé¿å…å› é…ç½®å˜æ›´å¯¼è‡´çš„åŠ è½½å¤±è´¥ã€‚</p>
<p>æœ€ååˆå¹¶ stateï¼ˆå¼ é‡æ•°æ®ï¼‰å’Œ param_groupsï¼ˆè¶…å‚æ•°é…ç½®ï¼‰ä¸ºå®Œæ•´çŠ¶æ€å­—å…¸ï¼Œé€šè¿‡ optimizer.load_state_dict å®Œæˆä¼˜åŒ–å™¨çŠ¶æ€æ¢å¤ã€‚</p>
<h2 id="_11">å·¥ç¨‹è°ƒç”¨</h2>
<h3 id="_12">åˆ›å»ºæµç¨‹</h3>
<div class="codehilite"><pre><span></span><code><span class="c1"># 1. ç­–ç•¥æä¾›å‚æ•°ï¼ˆå¦‚å¤šå‚æ•°ç»„ï¼‰</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">get_optim_params</span><span class="p">()</span>  <span class="c1"># ä¾‹å¦‚ï¼š{"backbone": [params1...], "head": [params2...]}</span>

<span class="c1"># 2. é…ç½®è§£æï¼šæ ¹æ® config.optimizer.type å®ä¾‹åŒ–å¯¹åº”å­ç±»ï¼ˆå¦‚ MultiAdamConfigï¼‰</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">MultiAdamConfig</span><span class="p">(</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">optimizer_groups</span><span class="o">=</span><span class="p">{</span><span class="s2">"backbone"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"lr"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">},</span> <span class="s2">"head"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"lr"</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">}}</span>
<span class="p">)</span>

<span class="c1"># 3. åˆ›å»ºä¼˜åŒ–å™¨å®ä¾‹</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>  <span class="c1"># è¿”å›ï¼š{"backbone": Adam, "head": Adam}</span>
</code></pre></div>
<h3 id="_13">è®­ç»ƒæµç¨‹</h3>
<div class="codehilite"><pre><span></span><code><span class="k">def</span> <span class="nf">update_policy</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="c1"># å‰å‘ä¼ æ’­è®¡ç®—æŸå¤±</span>
    <span class="n">loss</span><span class="p">,</span> <span class="n">output_dict</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="c1"># åå‘ä¼ æ’­ä¸æ¢¯åº¦è£å‰ª</span>
    <span class="n">grad_scaler</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">grad_scaler</span><span class="o">.</span><span class="n">unscale_</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">grad_clip_norm</span><span class="p">)</span>
    <span class="c1"># å‚æ•°æ›´æ–°</span>
    <span class="n">grad_scaler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>  <span class="c1"># æ¸…ç©ºæ¢¯åº¦</span>
</code></pre></div></div>
  <div class="post-nav">
    <a class="prev" href="å…·èº«æ™ºèƒ½actç®—æ³•.html">â† å…·èº«æ™ºèƒ½ACTç®—æ³•</a>
    <a class="next" href="lerobotå­¦ä¹ ç‡è°ƒåº¦å™¨.html">lerobotå­¦ä¹ ç‡è°ƒåº¦å™¨ â†’</a>
  </div>
</article>

      </section>

      <aside class="right-panel">
        
      </aside>
    </main>

    <footer class="site-footer">
      <div class="container">Copyright Â©2022-2025 laumy ç‰ˆæƒæ‰€æœ‰</div>
    </footer>

    <script src="assets/site.js"></script>
  </body>
  </html>

